{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-24T12:48:55.044093Z",
     "start_time": "2025-07-24T12:48:54.945549Z"
    }
   },
   "source": [
    "import transformers\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "import os\n",
    "from nilearn.image import load_img\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "data_dir = 'data'\n",
    "pet_dir = \"data/ad_pet_huw\""
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T11:27:26.235099Z",
     "start_time": "2025-07-24T11:27:23.205742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "files = {}\n",
    "for file in os.listdir(pet_dir):\n",
    "    if file.endswith(\".nii\"):\n",
    "        img = load_img(os.path.join(pet_dir, file))\n",
    "        patient_id = file.split(\".\")[0].removeprefix('AD_normalised_')\n",
    "        print(f'Processing patient: {patient_id}')\n",
    "        # Convert the image to a PyTorch tensor\n",
    "        torch_img = torch.tensor(img.get_fdata(), dtype=torch.float32)\n",
    "        files[patient_id] =torch_img"
   ],
   "id": "747bf61390b1b9ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing patient: 002_S_5018\n",
      "Processing patient: 003_S_4136\n",
      "Processing patient: 003_S_4152\n",
      "Processing patient: 003_S_4373\n",
      "Processing patient: 003_S_4892\n",
      "Processing patient: 003_S_5165\n",
      "Processing patient: 003_S_5187\n",
      "Processing patient: 005_S_4707\n",
      "Processing patient: 005_S_4910\n",
      "Processing patient: 005_S_5038\n",
      "Processing patient: 005_S_5119\n",
      "Processing patient: 006_S_4153\n",
      "Processing patient: 006_S_4192\n",
      "Processing patient: 006_S_4546\n",
      "Processing patient: 006_S_4867\n",
      "Processing patient: 007_S_4568\n",
      "Processing patient: 007_S_4637\n",
      "Processing patient: 007_S_4911\n",
      "Processing patient: 007_S_5196\n",
      "Processing patient: 009_S_5027\n",
      "Processing patient: 009_S_5037\n",
      "Processing patient: 009_S_5224\n",
      "Processing patient: 009_S_5252\n",
      "Processing patient: 011_S_4827\n",
      "Processing patient: 011_S_4845\n",
      "Processing patient: 011_S_4906\n",
      "Processing patient: 011_S_4912\n",
      "Processing patient: 011_S_4949\n",
      "Processing patient: 013_S_5071\n",
      "Processing patient: 014_S_4039\n",
      "Processing patient: 014_S_4615\n",
      "Processing patient: 016_S_4009\n",
      "Processing patient: 016_S_4353\n",
      "Processing patient: 016_S_4583\n",
      "Processing patient: 016_S_4591\n",
      "Processing patient: 016_S_4887\n",
      "Processing patient: 016_S_4963\n",
      "Processing patient: 016_S_5032\n",
      "Processing patient: 016_S_5057\n",
      "Processing patient: 016_S_5251\n",
      "Processing patient: 018_S_4696\n",
      "Processing patient: 018_S_5240\n",
      "Processing patient: 019_S_4252\n",
      "Processing patient: 019_S_4477\n",
      "Processing patient: 019_S_4549\n",
      "Processing patient: 019_S_5012\n",
      "Processing patient: 019_S_5019\n",
      "Processing patient: 021_S_4718\n",
      "Processing patient: 021_S_4924\n",
      "Processing patient: 023_S_4501\n",
      "Processing patient: 023_S_5120\n",
      "Processing patient: 023_S_5241\n",
      "Processing patient: 024_S_4223\n",
      "Processing patient: 024_S_4280\n",
      "Processing patient: 024_S_4905\n",
      "Processing patient: 024_S_5054\n",
      "Processing patient: 027_S_4801\n",
      "Processing patient: 027_S_4802\n",
      "Processing patient: 027_S_4938\n",
      "Processing patient: 027_S_4962\n",
      "Processing patient: 027_S_4964\n",
      "Processing patient: 029_S_4307\n",
      "Processing patient: 031_S_4024\n",
      "Processing patient: 032_S_4755\n",
      "Processing patient: 033_S_5013\n",
      "Processing patient: 033_S_5017\n",
      "Processing patient: 033_S_5087\n",
      "Processing patient: 035_S_4783\n",
      "Processing patient: 036_S_4740\n",
      "Processing patient: 036_S_4820\n",
      "Processing patient: 036_S_4894\n",
      "Processing patient: 036_S_5063\n",
      "Processing patient: 036_S_5112\n",
      "Processing patient: 036_S_5210\n",
      "Processing patient: 037_S_4001\n",
      "Processing patient: 037_S_4770\n",
      "Processing patient: 037_S_4879\n",
      "Processing patient: 037_S_5162\n",
      "Processing patient: 051_S_4980\n",
      "Processing patient: 051_S_5005\n",
      "Processing patient: 052_S_4959\n",
      "Processing patient: 052_S_5062\n",
      "Processing patient: 053_S_5070\n",
      "Processing patient: 053_S_5208\n",
      "Processing patient: 067_S_4728\n",
      "Processing patient: 067_S_5205\n",
      "Processing patient: 068_S_4859\n",
      "Processing patient: 068_S_4968\n",
      "Processing patient: 068_S_5146\n",
      "Processing patient: 070_S_4692\n",
      "Processing patient: 070_S_4719\n",
      "Processing patient: 073_S_4853\n",
      "Processing patient: 073_S_5016\n",
      "Processing patient: 073_S_5090\n",
      "Processing patient: 082_S_5029\n",
      "Processing patient: 082_S_5184\n",
      "Processing patient: 094_S_4089\n",
      "Processing patient: 094_S_4282\n",
      "Processing patient: 094_S_4737\n",
      "Processing patient: 098_S_4095\n",
      "Processing patient: 098_S_4201\n",
      "Processing patient: 098_S_4215\n",
      "Processing patient: 099_S_4994\n",
      "Processing patient: 100_S_5106\n",
      "Processing patient: 114_S_4379\n",
      "Processing patient: 116_S_4195\n",
      "Processing patient: 116_S_4209\n",
      "Processing patient: 116_S_4338\n",
      "Processing patient: 116_S_4625\n",
      "Processing patient: 116_S_4732\n",
      "Processing patient: 123_S_4526\n",
      "Processing patient: 126_S_4494\n",
      "Processing patient: 126_S_4686\n",
      "Processing patient: 127_S_4500\n",
      "Processing patient: 127_S_4940\n",
      "Processing patient: 127_S_4992\n",
      "Processing patient: 127_S_5028\n",
      "Processing patient: 127_S_5056\n",
      "Processing patient: 127_S_5058\n",
      "Processing patient: 127_S_5067\n",
      "Processing patient: 127_S_5095\n",
      "Processing patient: 128_S_4772\n",
      "Processing patient: 128_S_4774\n",
      "Processing patient: 128_S_4792\n",
      "Processing patient: 128_S_5123\n",
      "Processing patient: 130_S_4589\n",
      "Processing patient: 130_S_4641\n",
      "Processing patient: 130_S_4660\n",
      "Processing patient: 130_S_4730\n",
      "Processing patient: 130_S_4971\n",
      "Processing patient: 130_S_4982\n",
      "Processing patient: 130_S_4984\n",
      "Processing patient: 130_S_4990\n",
      "Processing patient: 130_S_4997\n",
      "Processing patient: 130_S_5006\n",
      "Processing patient: 130_S_5059\n",
      "Processing patient: 130_S_5231\n",
      "Processing patient: 131_S_5138\n",
      "Processing patient: 135_S_4657\n",
      "Processing patient: 135_S_4676\n",
      "Processing patient: 135_S_4863\n",
      "Processing patient: 135_S_4954\n",
      "Processing patient: 135_S_5015\n",
      "Processing patient: 135_S_5275\n",
      "Processing patient: 137_S_4211\n",
      "Processing patient: 137_S_4258\n",
      "Processing patient: 137_S_4672\n",
      "Processing patient: 137_S_4756\n",
      "Processing patient: 153_S_4172\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T11:27:26.837925Z",
     "start_time": "2025-07-24T11:27:26.648274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(os.path.join(data_dir, 'ADNIMERGE_19Jun2025.csv'))\n",
    "sex_df = df.filter(['PTID', 'PTGENDER'])\n",
    "sex_map = {'Male': 0, 'Female': 1}\n",
    "sex_labels = {0: 'Male', 1: 'Female'}\n",
    "sex_df['PTGENDER'] = sex_df['PTGENDER'].map(sex_map)"
   ],
   "id": "79ae1aae983dd038",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhruv Khanna\\AppData\\Local\\Temp\\ipykernel_16032\\804732265.py:1: DtypeWarning: Columns (19,20,21,50,51,104,105,106) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(data_dir, 'ADNIMERGE_19Jun2025.csv'))\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T11:29:18.845508Z",
     "start_time": "2025-07-24T11:29:18.819099Z"
    }
   },
   "cell_type": "code",
   "source": [
    "del df\n",
    "gc.collect()"
   ],
   "id": "2a374d69321325eb",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mdel\u001B[39;00m \u001B[43mdf\u001B[49m\n\u001B[32m      2\u001B[39m gc.collect()\n",
      "\u001B[31mNameError\u001B[39m: name 'df' is not defined"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T11:27:30.126855Z",
     "start_time": "2025-07-24T11:27:30.103038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compute the number of common patients between the PET files and the sex_df\n",
    "missing_patients = sex_df[~sex_df['PTID'].isin(files.keys())]\n",
    "print(f'Missing patients: {len(missing_patients)}')\n",
    "\n",
    "common_patients = sex_df['PTID'].isin(files.keys())\n",
    "print(f'Common patients: {common_patients.sum()}')\n",
    "\n",
    "print(f'Total patients {len(files)}')"
   ],
   "id": "696db8e9b1a77e3b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing patients: 15684\n",
      "Common patients: 737\n",
      "Total patients 149\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T11:27:31.299399Z",
     "start_time": "2025-07-24T11:27:31.114519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Update the sex DataFrame to include a new column for the PET image data matched on PTID\n",
    "for patient in files:\n",
    "    img = files.get(patient)\n",
    "    sex_df['PET_IMAGE'] = sex_df['PTID'].map(files) # Insert the img data ino the 'PET_IMAGE' column in sex_df for the corresponding PTID field"
   ],
   "id": "6972044d43a0ea82",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T11:27:31.995765Z",
     "start_time": "2025-07-24T11:27:31.987039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print the PTID for the columns for which PET_IMAGE is not None\n",
    "print(f'Number of patients: {len(sex_df)}')\n",
    "sex_df.dropna(subset=['PET_IMAGE'], inplace=True)\n",
    "sex_df.drop_duplicates(subset=['PTID'], inplace=True)\n",
    "print(f'Number of patients with PET images: {len(sex_df)}')"
   ],
   "id": "f18888aef471ede9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patients: 16421\n",
      "Number of patients with PET images: 149\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T11:28:27.690636Z",
     "start_time": "2025-07-24T11:28:27.684330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print the shape of the PET image for the first patient\n",
    "first_patient = sex_df.iloc[0]\n",
    "print(f'First patient PTID: {first_patient[\"PTID\"]}')\n",
    "print(f'PET image shape: {first_patient[\"PET_IMAGE\"].shape} with data type {type(first_patient[\"PET_IMAGE\"])}')\n",
    "print(f'Sex: {first_patient[\"PTGENDER\"]}')"
   ],
   "id": "d9176747064842ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First patient PTID: 135_S_5275\n",
      "PET image shape: torch.Size([101, 116, 96]) with data type <class 'torch.Tensor'>\n",
      "Sex: 1\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T11:30:14.393862Z",
     "start_time": "2025-07-24T11:30:14.388023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Select PET_IMAGE and PTGENDER from sex_df\n",
    "X = sex_df['PET_IMAGE'].tolist()  # This will be a list of torch.Tensor objects\n",
    "y = sex_df['PTGENDER'].values     # This will be a numpy array of labels\n",
    "\n",
    "print(f'X length: {len(X)}, PET image shape: {X[0].shape}, y shape: {y.shape}')"
   ],
   "id": "f04aba63a8c550",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X length: 149, PET image shape: torch.Size([101, 116, 96]), y shape: (149,)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T11:30:23.594869Z",
     "start_time": "2025-07-24T11:30:23.587993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)\n",
    "print(f'Train X length: {len(X_train)}, Test X length: {len(X_test)} with shapes {X_train[0].shape}, {X_test[0].shape}')\n",
    "print(f'Train y shape: {y_train.shape}, Test y shape: {y_test.shape}')"
   ],
   "id": "26f6414232ff88f2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X length: 119, Test X length: 30 with shapes torch.Size([101, 116, 96]), torch.Size([101, 116, 96])\n",
      "Train y shape: (119,), Test y shape: (30,)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T12:02:57.016074Z",
     "start_time": "2025-07-24T12:02:56.323797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.makedirs('data/pet_demographic', exist_ok=True)\n",
    "# Save the training and test data\n",
    "torch.save(X_train, 'data/pet_demographic/X_train.pt')\n",
    "torch.save(X_test, 'data/pet_demographic/X_test.pt')\n",
    "torch.save(y_train, 'data/pet_demographic/y_train.pt')\n",
    "torch.save(y_test, 'data/pet_demographic/y_test.pt')"
   ],
   "id": "d165e54d4a341253",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T12:49:02.894622Z",
     "start_time": "2025-07-24T12:49:01.849058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train = torch.load('data/pet_demographic/X_train.pt', weights_only=False)\n",
    "X_test = torch.load('data/pet_demographic/X_test.pt', weights_only=False)\n",
    "y_train = torch.load('data/pet_demographic/y_train.pt', weights_only=False)\n",
    "y_test = torch.load('data/pet_demographic/y_test.pt', weights_only=False)"
   ],
   "id": "20306e9e0b9215df",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T12:49:03.552663Z",
     "start_time": "2025-07-24T12:49:03.543649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PETDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        return image.unsqueeze(0), label  # Add channel dimension for CNN input"
   ],
   "id": "fe93456d764bb871",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T12:49:04.642037Z",
     "start_time": "2025-07-24T12:49:04.631121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a 3D CNN to deal with images of shape (101, 116, 96)\n",
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv3d(1, 16, kernel_size=5, padding='valid')\n",
    "        self.conv2 = torch.nn.Conv3d(16, 32, kernel_size=5, padding='valid')\n",
    "        self.pool = torch.nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "        self.fc1 = torch.nn.Linear(32 * 46 * 54 * 44, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 1)  # Output layer for binary classification\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.pool(x)  # Apply max pooling\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = self.fc1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ],
   "id": "a4c1e2a517af1973",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T17:49:56.057632Z",
     "start_time": "2025-07-24T12:49:08.668097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.cuda.empty_cache()\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "inputs = torch.stack([torch.unsqueeze(img, 0) for img in X_train], dim=0)  # Add channel dimension\n",
    "labels = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)  # Convert labels to float and add a channel dimension\n",
    "model = CNN().to(device)\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 100\n",
    "train_losses = []\n",
    "\n",
    "batch_size = 2  # Adjust based on your GPU memory\n",
    "train_dataset = PETDataset(X_train, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "total_batches = len(train_loader)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    batch_counter = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
    "        batch_counter += 1\n",
    "        print(f'Processing batch {batch_counter}/{total_batches} of epoch {epoch}')\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "        # Save the best model based on loss\n",
    "        if loss.item() < min(train_losses, default=float('inf')):\n",
    "            torch.save(model.state_dict(), 'data/pet_demographic/best_pet_cnn_model.pth')\n",
    "    del inputs, labels, outputs  # Clear variables to free memory\n",
    "    torch.cuda.empty_cache()  # Clear GPU memory after each epoch\n",
    "    gc.collect()  # Collect garbage to free up memory\n",
    "\n",
    "    print(f'Epoch [{epoch}/{epochs}], Loss: {loss.item():.4f}')"
   ],
   "id": "90be1cbe60d3816f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Processing batch 1/30 of epoch 1\n",
      "Processing batch 2/30 of epoch 1\n",
      "Processing batch 3/30 of epoch 1\n",
      "Processing batch 4/30 of epoch 1\n",
      "Processing batch 5/30 of epoch 1\n",
      "Processing batch 6/30 of epoch 1\n",
      "Processing batch 7/30 of epoch 1\n",
      "Processing batch 8/30 of epoch 1\n",
      "Processing batch 9/30 of epoch 1\n",
      "Processing batch 10/30 of epoch 1\n",
      "Processing batch 11/30 of epoch 1\n",
      "Processing batch 12/30 of epoch 1\n",
      "Processing batch 13/30 of epoch 1\n",
      "Processing batch 14/30 of epoch 1\n",
      "Processing batch 15/30 of epoch 1\n",
      "Processing batch 16/30 of epoch 1\n",
      "Processing batch 17/30 of epoch 1\n",
      "Processing batch 18/30 of epoch 1\n",
      "Processing batch 19/30 of epoch 1\n",
      "Processing batch 20/30 of epoch 1\n",
      "Processing batch 21/30 of epoch 1\n",
      "Processing batch 22/30 of epoch 1\n",
      "Processing batch 23/30 of epoch 1\n",
      "Processing batch 24/30 of epoch 1\n",
      "Processing batch 25/30 of epoch 1\n",
      "Processing batch 26/30 of epoch 1\n",
      "Processing batch 27/30 of epoch 1\n",
      "Processing batch 28/30 of epoch 1\n",
      "Processing batch 29/30 of epoch 1\n",
      "Processing batch 30/30 of epoch 1\n",
      "Processing batch 31/30 of epoch 1\n",
      "Processing batch 32/30 of epoch 1\n",
      "Processing batch 33/30 of epoch 1\n",
      "Processing batch 34/30 of epoch 1\n",
      "Processing batch 35/30 of epoch 1\n",
      "Processing batch 36/30 of epoch 1\n",
      "Processing batch 37/30 of epoch 1\n",
      "Processing batch 38/30 of epoch 1\n",
      "Processing batch 39/30 of epoch 1\n",
      "Processing batch 40/30 of epoch 1\n",
      "Processing batch 41/30 of epoch 1\n",
      "Processing batch 42/30 of epoch 1\n",
      "Processing batch 43/30 of epoch 1\n",
      "Processing batch 44/30 of epoch 1\n",
      "Processing batch 45/30 of epoch 1\n",
      "Processing batch 46/30 of epoch 1\n",
      "Processing batch 47/30 of epoch 1\n",
      "Processing batch 48/30 of epoch 1\n",
      "Processing batch 49/30 of epoch 1\n",
      "Processing batch 50/30 of epoch 1\n",
      "Processing batch 51/30 of epoch 1\n",
      "Processing batch 52/30 of epoch 1\n",
      "Processing batch 53/30 of epoch 1\n",
      "Processing batch 54/30 of epoch 1\n",
      "Processing batch 55/30 of epoch 1\n",
      "Processing batch 56/30 of epoch 1\n",
      "Processing batch 57/30 of epoch 1\n",
      "Processing batch 58/30 of epoch 1\n",
      "Processing batch 59/30 of epoch 1\n",
      "Processing batch 60/30 of epoch 1\n",
      "Epoch [1/100], Loss: 0.0000\n",
      "Processing batch 1/30 of epoch 2\n",
      "Processing batch 2/30 of epoch 2\n",
      "Processing batch 3/30 of epoch 2\n",
      "Processing batch 4/30 of epoch 2\n",
      "Processing batch 5/30 of epoch 2\n",
      "Processing batch 6/30 of epoch 2\n",
      "Processing batch 7/30 of epoch 2\n",
      "Processing batch 8/30 of epoch 2\n",
      "Processing batch 9/30 of epoch 2\n",
      "Processing batch 10/30 of epoch 2\n",
      "Processing batch 11/30 of epoch 2\n",
      "Processing batch 12/30 of epoch 2\n",
      "Processing batch 13/30 of epoch 2\n",
      "Processing batch 14/30 of epoch 2\n",
      "Processing batch 15/30 of epoch 2\n",
      "Processing batch 16/30 of epoch 2\n",
      "Processing batch 17/30 of epoch 2\n",
      "Processing batch 18/30 of epoch 2\n",
      "Processing batch 19/30 of epoch 2\n",
      "Processing batch 20/30 of epoch 2\n",
      "Processing batch 21/30 of epoch 2\n",
      "Processing batch 22/30 of epoch 2\n",
      "Processing batch 23/30 of epoch 2\n",
      "Processing batch 24/30 of epoch 2\n",
      "Processing batch 25/30 of epoch 2\n",
      "Processing batch 26/30 of epoch 2\n",
      "Processing batch 27/30 of epoch 2\n",
      "Processing batch 28/30 of epoch 2\n",
      "Processing batch 29/30 of epoch 2\n",
      "Processing batch 30/30 of epoch 2\n",
      "Processing batch 31/30 of epoch 2\n",
      "Processing batch 32/30 of epoch 2\n",
      "Processing batch 33/30 of epoch 2\n",
      "Processing batch 34/30 of epoch 2\n",
      "Processing batch 35/30 of epoch 2\n",
      "Processing batch 36/30 of epoch 2\n",
      "Processing batch 37/30 of epoch 2\n",
      "Processing batch 38/30 of epoch 2\n",
      "Processing batch 39/30 of epoch 2\n",
      "Processing batch 40/30 of epoch 2\n",
      "Processing batch 41/30 of epoch 2\n",
      "Processing batch 42/30 of epoch 2\n",
      "Processing batch 43/30 of epoch 2\n",
      "Processing batch 44/30 of epoch 2\n",
      "Processing batch 45/30 of epoch 2\n",
      "Processing batch 46/30 of epoch 2\n",
      "Processing batch 47/30 of epoch 2\n",
      "Processing batch 48/30 of epoch 2\n",
      "Processing batch 49/30 of epoch 2\n",
      "Processing batch 50/30 of epoch 2\n",
      "Processing batch 51/30 of epoch 2\n",
      "Processing batch 52/30 of epoch 2\n",
      "Processing batch 53/30 of epoch 2\n",
      "Processing batch 54/30 of epoch 2\n",
      "Processing batch 55/30 of epoch 2\n",
      "Processing batch 56/30 of epoch 2\n",
      "Processing batch 57/30 of epoch 2\n",
      "Processing batch 58/30 of epoch 2\n",
      "Processing batch 59/30 of epoch 2\n",
      "Processing batch 60/30 of epoch 2\n",
      "Epoch [2/100], Loss: 0.0000\n",
      "Processing batch 1/30 of epoch 3\n",
      "Processing batch 2/30 of epoch 3\n",
      "Processing batch 3/30 of epoch 3\n",
      "Processing batch 4/30 of epoch 3\n",
      "Processing batch 5/30 of epoch 3\n",
      "Processing batch 6/30 of epoch 3\n",
      "Processing batch 7/30 of epoch 3\n",
      "Processing batch 8/30 of epoch 3\n",
      "Processing batch 9/30 of epoch 3\n",
      "Processing batch 10/30 of epoch 3\n",
      "Processing batch 11/30 of epoch 3\n",
      "Processing batch 12/30 of epoch 3\n",
      "Processing batch 13/30 of epoch 3\n",
      "Processing batch 14/30 of epoch 3\n",
      "Processing batch 15/30 of epoch 3\n",
      "Processing batch 16/30 of epoch 3\n",
      "Processing batch 17/30 of epoch 3\n",
      "Processing batch 18/30 of epoch 3\n",
      "Processing batch 19/30 of epoch 3\n",
      "Processing batch 20/30 of epoch 3\n",
      "Processing batch 21/30 of epoch 3\n",
      "Processing batch 22/30 of epoch 3\n",
      "Processing batch 23/30 of epoch 3\n",
      "Processing batch 24/30 of epoch 3\n",
      "Processing batch 25/30 of epoch 3\n",
      "Processing batch 26/30 of epoch 3\n",
      "Processing batch 27/30 of epoch 3\n",
      "Processing batch 28/30 of epoch 3\n",
      "Processing batch 29/30 of epoch 3\n",
      "Processing batch 30/30 of epoch 3\n",
      "Processing batch 31/30 of epoch 3\n",
      "Processing batch 32/30 of epoch 3\n",
      "Processing batch 33/30 of epoch 3\n",
      "Processing batch 34/30 of epoch 3\n",
      "Processing batch 35/30 of epoch 3\n",
      "Processing batch 36/30 of epoch 3\n",
      "Processing batch 37/30 of epoch 3\n",
      "Processing batch 38/30 of epoch 3\n",
      "Processing batch 39/30 of epoch 3\n",
      "Processing batch 40/30 of epoch 3\n",
      "Processing batch 41/30 of epoch 3\n",
      "Processing batch 42/30 of epoch 3\n",
      "Processing batch 43/30 of epoch 3\n",
      "Processing batch 44/30 of epoch 3\n",
      "Processing batch 45/30 of epoch 3\n",
      "Processing batch 46/30 of epoch 3\n",
      "Processing batch 47/30 of epoch 3\n",
      "Processing batch 48/30 of epoch 3\n",
      "Processing batch 49/30 of epoch 3\n",
      "Processing batch 50/30 of epoch 3\n",
      "Processing batch 51/30 of epoch 3\n",
      "Processing batch 52/30 of epoch 3\n",
      "Processing batch 53/30 of epoch 3\n",
      "Processing batch 54/30 of epoch 3\n",
      "Processing batch 55/30 of epoch 3\n",
      "Processing batch 56/30 of epoch 3\n",
      "Processing batch 57/30 of epoch 3\n",
      "Processing batch 58/30 of epoch 3\n",
      "Processing batch 59/30 of epoch 3\n",
      "Processing batch 60/30 of epoch 3\n",
      "Epoch [3/100], Loss: 0.0000\n",
      "Processing batch 1/30 of epoch 4\n",
      "Processing batch 2/30 of epoch 4\n",
      "Processing batch 3/30 of epoch 4\n",
      "Processing batch 4/30 of epoch 4\n",
      "Processing batch 5/30 of epoch 4\n",
      "Processing batch 6/30 of epoch 4\n",
      "Processing batch 7/30 of epoch 4\n",
      "Processing batch 8/30 of epoch 4\n",
      "Processing batch 9/30 of epoch 4\n",
      "Processing batch 10/30 of epoch 4\n",
      "Processing batch 11/30 of epoch 4\n",
      "Processing batch 12/30 of epoch 4\n",
      "Processing batch 13/30 of epoch 4\n",
      "Processing batch 14/30 of epoch 4\n",
      "Processing batch 15/30 of epoch 4\n",
      "Processing batch 16/30 of epoch 4\n",
      "Processing batch 17/30 of epoch 4\n",
      "Processing batch 18/30 of epoch 4\n",
      "Processing batch 19/30 of epoch 4\n",
      "Processing batch 20/30 of epoch 4\n",
      "Processing batch 21/30 of epoch 4\n",
      "Processing batch 22/30 of epoch 4\n",
      "Processing batch 23/30 of epoch 4\n",
      "Processing batch 24/30 of epoch 4\n",
      "Processing batch 25/30 of epoch 4\n",
      "Processing batch 26/30 of epoch 4\n",
      "Processing batch 27/30 of epoch 4\n",
      "Processing batch 28/30 of epoch 4\n",
      "Processing batch 29/30 of epoch 4\n",
      "Processing batch 30/30 of epoch 4\n",
      "Processing batch 31/30 of epoch 4\n",
      "Processing batch 32/30 of epoch 4\n",
      "Processing batch 33/30 of epoch 4\n",
      "Processing batch 34/30 of epoch 4\n",
      "Processing batch 35/30 of epoch 4\n",
      "Processing batch 36/30 of epoch 4\n",
      "Processing batch 37/30 of epoch 4\n",
      "Processing batch 38/30 of epoch 4\n",
      "Processing batch 39/30 of epoch 4\n",
      "Processing batch 40/30 of epoch 4\n",
      "Processing batch 41/30 of epoch 4\n",
      "Processing batch 42/30 of epoch 4\n",
      "Processing batch 43/30 of epoch 4\n",
      "Processing batch 44/30 of epoch 4\n",
      "Processing batch 45/30 of epoch 4\n",
      "Processing batch 46/30 of epoch 4\n",
      "Processing batch 47/30 of epoch 4\n",
      "Processing batch 48/30 of epoch 4\n",
      "Processing batch 49/30 of epoch 4\n",
      "Processing batch 50/30 of epoch 4\n",
      "Processing batch 51/30 of epoch 4\n",
      "Processing batch 52/30 of epoch 4\n",
      "Processing batch 53/30 of epoch 4\n",
      "Processing batch 54/30 of epoch 4\n",
      "Processing batch 55/30 of epoch 4\n",
      "Processing batch 56/30 of epoch 4\n",
      "Processing batch 57/30 of epoch 4\n",
      "Processing batch 58/30 of epoch 4\n",
      "Processing batch 59/30 of epoch 4\n",
      "Processing batch 60/30 of epoch 4\n",
      "Epoch [4/100], Loss: 100.0000\n",
      "Processing batch 1/30 of epoch 5\n",
      "Processing batch 2/30 of epoch 5\n",
      "Processing batch 3/30 of epoch 5\n",
      "Processing batch 4/30 of epoch 5\n",
      "Processing batch 5/30 of epoch 5\n",
      "Processing batch 6/30 of epoch 5\n",
      "Processing batch 7/30 of epoch 5\n",
      "Processing batch 8/30 of epoch 5\n",
      "Processing batch 9/30 of epoch 5\n",
      "Processing batch 10/30 of epoch 5\n",
      "Processing batch 11/30 of epoch 5\n",
      "Processing batch 12/30 of epoch 5\n",
      "Processing batch 13/30 of epoch 5\n",
      "Processing batch 14/30 of epoch 5\n",
      "Processing batch 15/30 of epoch 5\n",
      "Processing batch 16/30 of epoch 5\n",
      "Processing batch 17/30 of epoch 5\n",
      "Processing batch 18/30 of epoch 5\n",
      "Processing batch 19/30 of epoch 5\n",
      "Processing batch 20/30 of epoch 5\n",
      "Processing batch 21/30 of epoch 5\n",
      "Processing batch 22/30 of epoch 5\n",
      "Processing batch 23/30 of epoch 5\n",
      "Processing batch 24/30 of epoch 5\n",
      "Processing batch 25/30 of epoch 5\n",
      "Processing batch 26/30 of epoch 5\n",
      "Processing batch 27/30 of epoch 5\n",
      "Processing batch 28/30 of epoch 5\n",
      "Processing batch 29/30 of epoch 5\n",
      "Processing batch 30/30 of epoch 5\n",
      "Processing batch 31/30 of epoch 5\n",
      "Processing batch 32/30 of epoch 5\n",
      "Processing batch 33/30 of epoch 5\n",
      "Processing batch 34/30 of epoch 5\n",
      "Processing batch 35/30 of epoch 5\n",
      "Processing batch 36/30 of epoch 5\n",
      "Processing batch 37/30 of epoch 5\n",
      "Processing batch 38/30 of epoch 5\n",
      "Processing batch 39/30 of epoch 5\n",
      "Processing batch 40/30 of epoch 5\n",
      "Processing batch 41/30 of epoch 5\n",
      "Processing batch 42/30 of epoch 5\n",
      "Processing batch 43/30 of epoch 5\n",
      "Processing batch 44/30 of epoch 5\n",
      "Processing batch 45/30 of epoch 5\n",
      "Processing batch 46/30 of epoch 5\n",
      "Processing batch 47/30 of epoch 5\n",
      "Processing batch 48/30 of epoch 5\n",
      "Processing batch 49/30 of epoch 5\n",
      "Processing batch 50/30 of epoch 5\n",
      "Processing batch 51/30 of epoch 5\n",
      "Processing batch 52/30 of epoch 5\n",
      "Processing batch 53/30 of epoch 5\n",
      "Processing batch 54/30 of epoch 5\n",
      "Processing batch 55/30 of epoch 5\n",
      "Processing batch 56/30 of epoch 5\n",
      "Processing batch 57/30 of epoch 5\n",
      "Processing batch 58/30 of epoch 5\n",
      "Processing batch 59/30 of epoch 5\n",
      "Processing batch 60/30 of epoch 5\n",
      "Epoch [5/100], Loss: 0.0000\n",
      "Processing batch 1/30 of epoch 6\n",
      "Processing batch 2/30 of epoch 6\n",
      "Processing batch 3/30 of epoch 6\n",
      "Processing batch 4/30 of epoch 6\n",
      "Processing batch 5/30 of epoch 6\n",
      "Processing batch 6/30 of epoch 6\n",
      "Processing batch 7/30 of epoch 6\n",
      "Processing batch 8/30 of epoch 6\n",
      "Processing batch 9/30 of epoch 6\n",
      "Processing batch 10/30 of epoch 6\n",
      "Processing batch 11/30 of epoch 6\n",
      "Processing batch 12/30 of epoch 6\n",
      "Processing batch 13/30 of epoch 6\n",
      "Processing batch 14/30 of epoch 6\n",
      "Processing batch 15/30 of epoch 6\n",
      "Processing batch 16/30 of epoch 6\n",
      "Processing batch 17/30 of epoch 6\n",
      "Processing batch 18/30 of epoch 6\n",
      "Processing batch 19/30 of epoch 6\n",
      "Processing batch 20/30 of epoch 6\n",
      "Processing batch 21/30 of epoch 6\n",
      "Processing batch 22/30 of epoch 6\n",
      "Processing batch 23/30 of epoch 6\n",
      "Processing batch 24/30 of epoch 6\n",
      "Processing batch 25/30 of epoch 6\n",
      "Processing batch 26/30 of epoch 6\n",
      "Processing batch 27/30 of epoch 6\n",
      "Processing batch 28/30 of epoch 6\n",
      "Processing batch 29/30 of epoch 6\n",
      "Processing batch 30/30 of epoch 6\n",
      "Processing batch 31/30 of epoch 6\n",
      "Processing batch 32/30 of epoch 6\n",
      "Processing batch 33/30 of epoch 6\n",
      "Processing batch 34/30 of epoch 6\n",
      "Processing batch 35/30 of epoch 6\n",
      "Processing batch 36/30 of epoch 6\n",
      "Processing batch 37/30 of epoch 6\n",
      "Processing batch 38/30 of epoch 6\n",
      "Processing batch 39/30 of epoch 6\n",
      "Processing batch 40/30 of epoch 6\n",
      "Processing batch 41/30 of epoch 6\n",
      "Processing batch 42/30 of epoch 6\n",
      "Processing batch 43/30 of epoch 6\n",
      "Processing batch 44/30 of epoch 6\n",
      "Processing batch 45/30 of epoch 6\n",
      "Processing batch 46/30 of epoch 6\n",
      "Processing batch 47/30 of epoch 6\n",
      "Processing batch 48/30 of epoch 6\n",
      "Processing batch 49/30 of epoch 6\n",
      "Processing batch 50/30 of epoch 6\n",
      "Processing batch 51/30 of epoch 6\n",
      "Processing batch 52/30 of epoch 6\n",
      "Processing batch 53/30 of epoch 6\n",
      "Processing batch 54/30 of epoch 6\n",
      "Processing batch 55/30 of epoch 6\n",
      "Processing batch 56/30 of epoch 6\n",
      "Processing batch 57/30 of epoch 6\n",
      "Processing batch 58/30 of epoch 6\n",
      "Processing batch 59/30 of epoch 6\n",
      "Processing batch 60/30 of epoch 6\n",
      "Epoch [6/100], Loss: 100.0000\n",
      "Processing batch 1/30 of epoch 7\n",
      "Processing batch 2/30 of epoch 7\n",
      "Processing batch 3/30 of epoch 7\n",
      "Processing batch 4/30 of epoch 7\n",
      "Processing batch 5/30 of epoch 7\n",
      "Processing batch 6/30 of epoch 7\n",
      "Processing batch 7/30 of epoch 7\n",
      "Processing batch 8/30 of epoch 7\n",
      "Processing batch 9/30 of epoch 7\n",
      "Processing batch 10/30 of epoch 7\n",
      "Processing batch 11/30 of epoch 7\n",
      "Processing batch 12/30 of epoch 7\n",
      "Processing batch 13/30 of epoch 7\n",
      "Processing batch 14/30 of epoch 7\n",
      "Processing batch 15/30 of epoch 7\n",
      "Processing batch 16/30 of epoch 7\n",
      "Processing batch 17/30 of epoch 7\n",
      "Processing batch 18/30 of epoch 7\n",
      "Processing batch 19/30 of epoch 7\n",
      "Processing batch 20/30 of epoch 7\n",
      "Processing batch 21/30 of epoch 7\n",
      "Processing batch 22/30 of epoch 7\n",
      "Processing batch 23/30 of epoch 7\n",
      "Processing batch 24/30 of epoch 7\n",
      "Processing batch 25/30 of epoch 7\n",
      "Processing batch 26/30 of epoch 7\n",
      "Processing batch 27/30 of epoch 7\n",
      "Processing batch 28/30 of epoch 7\n",
      "Processing batch 29/30 of epoch 7\n",
      "Processing batch 30/30 of epoch 7\n",
      "Processing batch 31/30 of epoch 7\n",
      "Processing batch 32/30 of epoch 7\n",
      "Processing batch 33/30 of epoch 7\n",
      "Processing batch 34/30 of epoch 7\n",
      "Processing batch 35/30 of epoch 7\n",
      "Processing batch 36/30 of epoch 7\n",
      "Processing batch 37/30 of epoch 7\n",
      "Processing batch 38/30 of epoch 7\n",
      "Processing batch 39/30 of epoch 7\n",
      "Processing batch 40/30 of epoch 7\n",
      "Processing batch 41/30 of epoch 7\n",
      "Processing batch 42/30 of epoch 7\n",
      "Processing batch 43/30 of epoch 7\n",
      "Processing batch 44/30 of epoch 7\n",
      "Processing batch 45/30 of epoch 7\n",
      "Processing batch 46/30 of epoch 7\n",
      "Processing batch 47/30 of epoch 7\n",
      "Processing batch 48/30 of epoch 7\n",
      "Processing batch 49/30 of epoch 7\n",
      "Processing batch 50/30 of epoch 7\n",
      "Processing batch 51/30 of epoch 7\n",
      "Processing batch 52/30 of epoch 7\n",
      "Processing batch 53/30 of epoch 7\n",
      "Processing batch 54/30 of epoch 7\n",
      "Processing batch 55/30 of epoch 7\n",
      "Processing batch 56/30 of epoch 7\n",
      "Processing batch 57/30 of epoch 7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 30\u001B[39m\n\u001B[32m     28\u001B[39m loss.backward()\n\u001B[32m     29\u001B[39m optimizer.step()\n\u001B[32m---> \u001B[39m\u001B[32m30\u001B[39m train_losses.append(\u001B[43mloss\u001B[49m\u001B[43m.\u001B[49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m     31\u001B[39m \u001B[38;5;66;03m# Save the best model based on loss\u001B[39;00m\n\u001B[32m     32\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m loss.item() < \u001B[38;5;28mmin\u001B[39m(train_losses, default=\u001B[38;5;28mfloat\u001B[39m(\u001B[33m'\u001B[39m\u001B[33minf\u001B[39m\u001B[33m'\u001B[39m)):\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.save(model.state_dict(), 'data/pet_demographic/pet_cnn_model.pth')",
   "id": "d7f46236ad2b8b9f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T18:04:37.991351Z",
     "start_time": "2025-07-24T17:56:43.615009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compute the accuracy on the train set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    train_dataset = PETDataset(X_train, y_train)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    y_pred_train = []\n",
    "    y_true_train = []\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
    "        outputs = model(inputs)\n",
    "        y_pred_train.extend(outputs.cpu().numpy())\n",
    "        y_true_train.extend(labels.cpu().numpy())\n",
    "    y_pred_train = (torch.tensor(y_pred_train) > 0.5).float().numpy()  # Convert probabilities to binary predictions\n",
    "    y_true_train = torch.tensor(y_true_train).numpy()\n",
    "    train_accuracy = accuracy_score(y_true_train, y_pred_train)\n",
    "    train_f1 = f1_score(y_true_train, y_pred_train)\n",
    "    train_roc_auc = roc_auc_score(y_true_train, y_pred_train)\n",
    "    print(f'Train Accuracy: {train_accuracy:.4f}, Train F1 Score: {train_f1:.4f}, Train ROC AUC: {train_roc_auc:.4f}')"
   ],
   "id": "2d3299edd155a6d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.4202, Train F1 Score: 0.5917, Train ROC AUC: 0.5000\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T17:55:35.349957Z",
     "start_time": "2025-07-24T17:53:33.534742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compute the accuracy on the test set\n",
    "with torch.no_grad():\n",
    "    test_dataset = PETDataset(X_test, y_test)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    y_pred_test = []\n",
    "    y_true_test = []\n",
    "\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
    "        outputs = model(inputs)\n",
    "        y_pred_test.extend(outputs.cpu().numpy())\n",
    "        y_true_test.extend(labels.cpu().numpy())\n",
    "    y_pred_test = (torch.tensor(y_pred_test) > 0.5).float().numpy()  # Convert probabilities to binary predictions\n",
    "    y_true_test = torch.tensor(y_true_test).numpy()\n",
    "    test_accuracy = accuracy_score(y_true_test, y_pred_test)\n",
    "    test_f1 = f1_score(y_true_test, y_pred_test)\n",
    "    test_roc_auc = roc_auc_score(y_true_test, y_pred_test)\n",
    "    print(f'Test Accuracy: {test_accuracy:.4f}, Test F1 Score: {test_f1:.4f}, Test ROC AUC: {test_roc_auc:.4f}')"
   ],
   "id": "a05c40a6233b6a4b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhruv Khanna\\AppData\\Local\\Temp\\ipykernel_25916\\3200254905.py:13: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:257.)\n",
      "  y_pred_test = (torch.tensor(y_pred_test) > 0.5).float().numpy()  # Convert probabilities to binary predictions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.4333, Test F1 Score: 0.6047, Test ROC AUC: 0.5000\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

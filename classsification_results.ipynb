{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "260279c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, confusion_matrix, roc_auc_score, roc_curve, f1_score, matthews_corrcoef\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "import mrmr\n",
    "import optuna\n",
    "import torch\n",
    "import gpytorch\n",
    "import torchmetrics\n",
    "\n",
    "data_dir = 'data'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ad96bed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUVr_ACC_pre_L.nii</th>\n",
       "      <th>SUVr_ACC_pre_R.nii</th>\n",
       "      <th>SUVr_ACC_sub_L.nii</th>\n",
       "      <th>SUVr_ACC_sub_R.nii</th>\n",
       "      <th>SUVr_ACC_sup_L.nii</th>\n",
       "      <th>SUVr_ACC_sup_R.nii</th>\n",
       "      <th>SUVr_Amygdala_L.nii</th>\n",
       "      <th>SUVr_Amygdala_R.nii</th>\n",
       "      <th>SUVr_Angular_L.nii</th>\n",
       "      <th>SUVr_Angular_R.nii</th>\n",
       "      <th>...</th>\n",
       "      <th>SUVr_Vermis_6.nii</th>\n",
       "      <th>SUVr_Vermis_7.nii</th>\n",
       "      <th>SUVr_Vermis_8.nii</th>\n",
       "      <th>SUVr_Vermis_9.nii</th>\n",
       "      <th>SUVr_Vermis_10.nii</th>\n",
       "      <th>SUVr_VTA_L.nii</th>\n",
       "      <th>SUVr_VTA_R.nii</th>\n",
       "      <th>A+</th>\n",
       "      <th>T+</th>\n",
       "      <th>N+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.031439</td>\n",
       "      <td>-0.939867</td>\n",
       "      <td>-0.941345</td>\n",
       "      <td>-0.953400</td>\n",
       "      <td>0.039320</td>\n",
       "      <td>0.038841</td>\n",
       "      <td>0.011054</td>\n",
       "      <td>0.014155</td>\n",
       "      <td>-1.532557</td>\n",
       "      <td>-1.429775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018253</td>\n",
       "      <td>0.009289</td>\n",
       "      <td>0.011917</td>\n",
       "      <td>0.008881</td>\n",
       "      <td>0.006231</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.190475</td>\n",
       "      <td>1.118614</td>\n",
       "      <td>1.144220</td>\n",
       "      <td>0.928409</td>\n",
       "      <td>0.057261</td>\n",
       "      <td>0.053242</td>\n",
       "      <td>0.013008</td>\n",
       "      <td>0.017184</td>\n",
       "      <td>1.740331</td>\n",
       "      <td>2.026532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016903</td>\n",
       "      <td>0.009108</td>\n",
       "      <td>0.012666</td>\n",
       "      <td>0.008033</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.481382</td>\n",
       "      <td>1.476620</td>\n",
       "      <td>1.518520</td>\n",
       "      <td>1.375084</td>\n",
       "      <td>0.054272</td>\n",
       "      <td>0.053113</td>\n",
       "      <td>0.013620</td>\n",
       "      <td>0.016730</td>\n",
       "      <td>1.590446</td>\n",
       "      <td>1.179038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019224</td>\n",
       "      <td>0.010413</td>\n",
       "      <td>0.012902</td>\n",
       "      <td>0.007799</td>\n",
       "      <td>0.005730</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.074118</td>\n",
       "      <td>-0.114674</td>\n",
       "      <td>-0.401073</td>\n",
       "      <td>-0.094141</td>\n",
       "      <td>0.044834</td>\n",
       "      <td>0.042373</td>\n",
       "      <td>0.011938</td>\n",
       "      <td>0.015462</td>\n",
       "      <td>-0.673442</td>\n",
       "      <td>-0.323968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019834</td>\n",
       "      <td>0.010011</td>\n",
       "      <td>0.012782</td>\n",
       "      <td>0.009789</td>\n",
       "      <td>0.006613</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.174385</td>\n",
       "      <td>-0.456932</td>\n",
       "      <td>-0.096572</td>\n",
       "      <td>-0.210932</td>\n",
       "      <td>0.042674</td>\n",
       "      <td>0.039067</td>\n",
       "      <td>0.011457</td>\n",
       "      <td>0.013684</td>\n",
       "      <td>-0.166624</td>\n",
       "      <td>-0.560099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017897</td>\n",
       "      <td>0.009361</td>\n",
       "      <td>0.012595</td>\n",
       "      <td>0.008533</td>\n",
       "      <td>0.005170</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>0.152440</td>\n",
       "      <td>0.187233</td>\n",
       "      <td>-0.566841</td>\n",
       "      <td>-0.202246</td>\n",
       "      <td>0.042117</td>\n",
       "      <td>0.045545</td>\n",
       "      <td>0.013725</td>\n",
       "      <td>0.016478</td>\n",
       "      <td>-1.175662</td>\n",
       "      <td>-1.357875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018864</td>\n",
       "      <td>0.008398</td>\n",
       "      <td>0.011478</td>\n",
       "      <td>0.009674</td>\n",
       "      <td>0.007555</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>-0.650453</td>\n",
       "      <td>-0.313642</td>\n",
       "      <td>-0.686054</td>\n",
       "      <td>-0.794358</td>\n",
       "      <td>0.040523</td>\n",
       "      <td>0.041999</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>0.014486</td>\n",
       "      <td>0.058629</td>\n",
       "      <td>0.597411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016943</td>\n",
       "      <td>0.008936</td>\n",
       "      <td>0.011930</td>\n",
       "      <td>0.008579</td>\n",
       "      <td>0.006243</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>-0.461427</td>\n",
       "      <td>-0.219473</td>\n",
       "      <td>-0.177314</td>\n",
       "      <td>-0.159231</td>\n",
       "      <td>0.046125</td>\n",
       "      <td>0.047444</td>\n",
       "      <td>0.010035</td>\n",
       "      <td>0.012790</td>\n",
       "      <td>-0.120657</td>\n",
       "      <td>-0.074618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015693</td>\n",
       "      <td>0.008374</td>\n",
       "      <td>0.011329</td>\n",
       "      <td>0.008016</td>\n",
       "      <td>0.006976</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>-1.544436</td>\n",
       "      <td>-1.012396</td>\n",
       "      <td>-1.230629</td>\n",
       "      <td>-1.135321</td>\n",
       "      <td>0.035993</td>\n",
       "      <td>0.039143</td>\n",
       "      <td>0.010660</td>\n",
       "      <td>0.014074</td>\n",
       "      <td>-0.860438</td>\n",
       "      <td>-0.772415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017387</td>\n",
       "      <td>0.008620</td>\n",
       "      <td>0.010525</td>\n",
       "      <td>0.007063</td>\n",
       "      <td>0.005713</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>0.037994</td>\n",
       "      <td>0.151474</td>\n",
       "      <td>0.235611</td>\n",
       "      <td>-0.202719</td>\n",
       "      <td>0.048793</td>\n",
       "      <td>0.048942</td>\n",
       "      <td>0.011703</td>\n",
       "      <td>0.017449</td>\n",
       "      <td>-0.011570</td>\n",
       "      <td>-0.444311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023225</td>\n",
       "      <td>0.010660</td>\n",
       "      <td>0.012455</td>\n",
       "      <td>0.008448</td>\n",
       "      <td>0.007024</td>\n",
       "      <td>0.000960</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>538 rows × 169 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SUVr_ACC_pre_L.nii  SUVr_ACC_pre_R.nii  SUVr_ACC_sub_L.nii  \\\n",
       "0             -1.031439           -0.939867           -0.941345   \n",
       "1              1.190475            1.118614            1.144220   \n",
       "2              1.481382            1.476620            1.518520   \n",
       "3             -0.074118           -0.114674           -0.401073   \n",
       "4             -0.174385           -0.456932           -0.096572   \n",
       "..                  ...                 ...                 ...   \n",
       "533            0.152440            0.187233           -0.566841   \n",
       "534           -0.650453           -0.313642           -0.686054   \n",
       "535           -0.461427           -0.219473           -0.177314   \n",
       "536           -1.544436           -1.012396           -1.230629   \n",
       "537            0.037994            0.151474            0.235611   \n",
       "\n",
       "     SUVr_ACC_sub_R.nii  SUVr_ACC_sup_L.nii  SUVr_ACC_sup_R.nii  \\\n",
       "0             -0.953400            0.039320            0.038841   \n",
       "1              0.928409            0.057261            0.053242   \n",
       "2              1.375084            0.054272            0.053113   \n",
       "3             -0.094141            0.044834            0.042373   \n",
       "4             -0.210932            0.042674            0.039067   \n",
       "..                  ...                 ...                 ...   \n",
       "533           -0.202246            0.042117            0.045545   \n",
       "534           -0.794358            0.040523            0.041999   \n",
       "535           -0.159231            0.046125            0.047444   \n",
       "536           -1.135321            0.035993            0.039143   \n",
       "537           -0.202719            0.048793            0.048942   \n",
       "\n",
       "     SUVr_Amygdala_L.nii  SUVr_Amygdala_R.nii  SUVr_Angular_L.nii  \\\n",
       "0               0.011054             0.014155           -1.532557   \n",
       "1               0.013008             0.017184            1.740331   \n",
       "2               0.013620             0.016730            1.590446   \n",
       "3               0.011938             0.015462           -0.673442   \n",
       "4               0.011457             0.013684           -0.166624   \n",
       "..                   ...                  ...                 ...   \n",
       "533             0.013725             0.016478           -1.175662   \n",
       "534             0.011000             0.014486            0.058629   \n",
       "535             0.010035             0.012790           -0.120657   \n",
       "536             0.010660             0.014074           -0.860438   \n",
       "537             0.011703             0.017449           -0.011570   \n",
       "\n",
       "     SUVr_Angular_R.nii  ...  SUVr_Vermis_6.nii  SUVr_Vermis_7.nii  \\\n",
       "0             -1.429775  ...           0.018253           0.009289   \n",
       "1              2.026532  ...           0.016903           0.009108   \n",
       "2              1.179038  ...           0.019224           0.010413   \n",
       "3             -0.323968  ...           0.019834           0.010011   \n",
       "4             -0.560099  ...           0.017897           0.009361   \n",
       "..                  ...  ...                ...                ...   \n",
       "533           -1.357875  ...           0.018864           0.008398   \n",
       "534            0.597411  ...           0.016943           0.008936   \n",
       "535           -0.074618  ...           0.015693           0.008374   \n",
       "536           -0.772415  ...           0.017387           0.008620   \n",
       "537           -0.444311  ...           0.023225           0.010660   \n",
       "\n",
       "     SUVr_Vermis_8.nii  SUVr_Vermis_9.nii  SUVr_Vermis_10.nii  SUVr_VTA_L.nii  \\\n",
       "0             0.011917           0.008881            0.006231        0.000712   \n",
       "1             0.012666           0.008033            0.006029        0.000770   \n",
       "2             0.012902           0.007799            0.005730        0.000804   \n",
       "3             0.012782           0.009789            0.006613        0.000748   \n",
       "4             0.012595           0.008533            0.005170        0.000675   \n",
       "..                 ...                ...                 ...             ...   \n",
       "533           0.011478           0.009674            0.007555        0.000818   \n",
       "534           0.011930           0.008579            0.006243        0.000678   \n",
       "535           0.011329           0.008016            0.006976        0.000753   \n",
       "536           0.010525           0.007063            0.005713        0.000815   \n",
       "537           0.012455           0.008448            0.007024        0.000960   \n",
       "\n",
       "     SUVr_VTA_R.nii  A+  T+  N+  \n",
       "0          0.000659   1   0   0  \n",
       "1          0.000699   1   1   1  \n",
       "2          0.000760   1   1   1  \n",
       "3          0.000675   1   0   0  \n",
       "4          0.000675   1   1   1  \n",
       "..              ...  ..  ..  ..  \n",
       "533        0.000764   0   0   0  \n",
       "534        0.000581   0   0   0  \n",
       "535        0.000723   0   0   0  \n",
       "536        0.000768   0   0   0  \n",
       "537        0.000931   1   0   0  \n",
       "\n",
       "[538 rows x 169 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = 'data'\n",
    "\n",
    "df = pd.read_csv(os.path.join(data_dir, 'final_data_log_targets_with_demographic.csv'))\n",
    "\n",
    "\n",
    "df['tau_ab_ratio'] = np.exp(df['TAU_bl']) / df['ABETA_bl']\n",
    "df['ptau_ab_ratio'] =np.exp(df['PTAU_bl']) / df['ABETA_bl']\n",
    "\n",
    "df['A+'] = df['ABETA_bl'].apply(lambda x: 1 if x < 880 else 0)\n",
    "df['T+'] = df['ptau_ab_ratio'].apply(lambda x: 1 if x > 0.028 else 0)\n",
    "df['N+'] = df['tau_ab_ratio'].apply(lambda x: 1 if x > 0.33 else 0)\n",
    "\n",
    "df =df.drop(columns=['DX_bl','DX','AGE','PTGENDER','PTRACCAT','FHQMOM','FHQMOMAD','FHQDAD','FHQDADAD','RAVLT_perc_forgetting_bl','PTEDUCAT','TAU_bl','PTAU_bl','ABETA_bl', 'MMSE_bl','EcogPtTotal_bl', 'LDELTOTAL_BL', 'mPACCdigit_bl', 'mPACCtrailsB_bl', 'RAVLT_immediate_bl', 'RAVLT_learning_bl', 'RAVLT_forgetting_bl','tau_ab_ratio',\t'ptau_ab_ratio'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b8d8f3",
   "metadata": {},
   "source": [
    "# STL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0d19632c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM(torch.nn.Module):\n",
    "    def __init__(self, features, targets, kernel: gpytorch.kernels.Kernel):\n",
    "        super().__init__()\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        self.kernel = kernel\n",
    "        self.w = torch.nn.Parameter(torch.randn(features.shape[1], 1), requires_grad=True)\n",
    "        self.b = torch.nn.Parameter(torch.randn(1), requires_grad=True)\n",
    "        self.classifier = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        plane_output = x.matmul(self.w) + self.b\n",
    "        return self.classifier(plane_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "26e191af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Train Metrics ===\n",
      "Accuracy:  0.848062015503876 ± 0.009744034953470197\n",
      "Precision: 0.8650804045307011 ± 0.016247478941485406\n",
      "Recall:    0.8212431390001482 ± 0.00912297395728929\n",
      "F1 Score:  0.8424841616770483 ± 0.00882714149336615\n",
      "AUROC:     0.8843371221486486 ± 0.007261757046355939\n",
      "\n",
      "=== Test Metrics ===\n",
      "Accuracy:  0.8703703703703702 ± 0.015120307054217125\n",
      "Precision: 0.8690476190476191 ± 0.01151081052195653\n",
      "Recall:    0.86996336996337 ± 0.04162387610755868\n",
      "F1 Score:  0.8687084520417855 ± 0.01530188323297435\n",
      "AUROC:     0.9075091575091575 ± 0.012358131979880622\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['A+', 'T+', 'N+'])\n",
    "y = df['A+']\n",
    "\n",
    "train_acc = []\n",
    "train_pre = []\n",
    "train_rec = []\n",
    "train_f1 = []\n",
    "train_auroc = []\n",
    "\n",
    "test_acc = []\n",
    "test_pre = []\n",
    "test_rec = []\n",
    "test_f1 = []\n",
    "test_auroc = []\n",
    "\n",
    "for i in range(0, 3):\n",
    "    rs = np.random.randint(0, 75)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=rs)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    y_train = torch.tensor(y_train.values, dtype=torch.float32).to(device).unsqueeze(1)\n",
    "    y_test = torch.tensor(y_test.values, dtype=torch.float32).to(device).unsqueeze(1)\n",
    "\n",
    "    model = SVM(X_train, y_train, kernel=gpytorch.kernels.RBFKernel()).to(device)\n",
    "    bhl = torchmetrics.classification.BinaryHingeLoss(squared=True).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "\n",
    "    # Training\n",
    "    for epoch in range(1, 101):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_train)\n",
    "        loss = bhl(output, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # EVAL: Train\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_train = model(X_train)\n",
    "        y_pred_train_labels = (y_pred_train > 0.5).float()\n",
    "        y_pred_train_np = y_pred_train_labels.cpu().numpy()\n",
    "        y_train_np = y_train.cpu().numpy()\n",
    "        y_pred_train_proba = y_pred_train.cpu().numpy()\n",
    "\n",
    "        train_acc.append(accuracy_score(y_train_np, y_pred_train_np))\n",
    "        train_pre.append(precision_score(y_train_np, y_pred_train_np))\n",
    "        train_rec.append(recall_score(y_train_np, y_pred_train_np))\n",
    "        train_f1.append(f1_score(y_train_np, y_pred_train_np))\n",
    "        train_auroc.append(roc_auc_score(y_train_np, y_pred_train_proba))\n",
    "\n",
    "    # EVAL: Test\n",
    "    with torch.no_grad():\n",
    "        y_pred_test = model(X_test)\n",
    "        y_pred_test_labels = (y_pred_test > 0.5).float()\n",
    "        y_pred_test_np = y_pred_test_labels.cpu().numpy()\n",
    "        y_test_np = y_test.cpu().numpy()\n",
    "        y_pred_test_proba = y_pred_test.cpu().numpy()\n",
    "\n",
    "        test_acc.append(accuracy_score(y_test_np, y_pred_test_np))\n",
    "        test_pre.append(precision_score(y_test_np, y_pred_test_np))\n",
    "        test_rec.append(recall_score(y_test_np, y_pred_test_np))\n",
    "        test_f1.append(f1_score(y_test_np, y_pred_test_np))\n",
    "        test_auroc.append(roc_auc_score(y_test_np, y_pred_test_proba))\n",
    "\n",
    "\n",
    "print(\"=== Train Metrics ===\")\n",
    "print(\"Accuracy: \", np.mean(train_acc), \"±\", np.std(train_acc))\n",
    "print(\"Precision:\", np.mean(train_pre), \"±\", np.std(train_pre))\n",
    "print(\"Recall:   \", np.mean(train_rec), \"±\", np.std(train_rec))\n",
    "print(\"F1 Score: \", np.mean(train_f1), \"±\", np.std(train_f1))\n",
    "print(\"AUROC:    \", np.mean(train_auroc), \"±\", np.std(train_auroc))\n",
    "\n",
    "print(\"\\n=== Test Metrics ===\")\n",
    "print(\"Accuracy: \", np.mean(test_acc), \"±\", np.std(test_acc))\n",
    "print(\"Precision:\", np.mean(test_pre), \"±\", np.std(test_pre))\n",
    "print(\"Recall:   \", np.mean(test_rec), \"±\", np.std(test_rec))\n",
    "print(\"F1 Score: \", np.mean(test_f1), \"±\", np.std(test_f1))\n",
    "print(\"AUROC:    \", np.mean(test_auroc), \"±\", np.std(test_auroc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "48c8ee8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Train Metrics ===\n",
      "Accuracy:  0.9224806201550387 ± 0.016371094637164997\n",
      "Precision: 0.9270652436097683 ± 0.011486234609613854\n",
      "Recall:    0.909160718834694 ± 0.024589684276704063\n",
      "F1 Score:  0.9179762038869878 ± 0.018134298707607563\n",
      "AUROC:     0.9595148728692062 ± 0.00031658878023908864\n",
      "\n",
      "=== Test Metrics ===\n",
      "Accuracy:  0.8950617283950617 ± 0.01573771454812586\n",
      "Precision: 0.8845707751368129 ± 0.02030793157185032\n",
      "Recall:    0.9068984474644853 ± 0.028419574362720825\n",
      "F1 Score:  0.8951702281034356 ± 0.01502310853215183\n",
      "AUROC:     0.9267357053324035 ± 0.011021385819993065\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['A+', 'T+', 'N+'])\n",
    "y = df['T+']\n",
    "\n",
    "train_acc = []\n",
    "train_pre = []\n",
    "train_rec = []\n",
    "train_f1 = []\n",
    "train_auroc = []\n",
    "\n",
    "test_acc = []\n",
    "test_pre = []\n",
    "test_rec = []\n",
    "test_f1 = []\n",
    "test_auroc = []\n",
    "\n",
    "for i in range(0, 3):\n",
    "    rs = np.random.randint(0, 75)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=rs)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    y_train = torch.tensor(y_train.values, dtype=torch.float32).to(device).unsqueeze(1)\n",
    "    y_test = torch.tensor(y_test.values, dtype=torch.float32).to(device).unsqueeze(1)\n",
    "\n",
    "    model = SVM(X_train, y_train, kernel=gpytorch.kernels.RBFKernel()).to(device)\n",
    "    bhl = torchmetrics.classification.BinaryHingeLoss(squared=True).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "\n",
    "    # Training\n",
    "    for epoch in range(1, 101):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_train)\n",
    "        loss = bhl(output, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # EVAL: Train\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_train = model(X_train)\n",
    "        y_pred_train_labels = (y_pred_train > 0.5).float()\n",
    "        y_pred_train_np = y_pred_train_labels.cpu().numpy()\n",
    "        y_train_np = y_train.cpu().numpy()\n",
    "        y_pred_train_proba = y_pred_train.cpu().numpy()\n",
    "\n",
    "        train_acc.append(accuracy_score(y_train_np, y_pred_train_np))\n",
    "        train_pre.append(precision_score(y_train_np, y_pred_train_np))\n",
    "        train_rec.append(recall_score(y_train_np, y_pred_train_np))\n",
    "        train_f1.append(f1_score(y_train_np, y_pred_train_np))\n",
    "        train_auroc.append(roc_auc_score(y_train_np, y_pred_train_proba))\n",
    "\n",
    "    # EVAL: Test\n",
    "    with torch.no_grad():\n",
    "        y_pred_test = model(X_test)\n",
    "        y_pred_test_labels = (y_pred_test > 0.5).float()\n",
    "        y_pred_test_np = y_pred_test_labels.cpu().numpy()\n",
    "        y_test_np = y_test.cpu().numpy()\n",
    "        y_pred_test_proba = y_pred_test.cpu().numpy()\n",
    "\n",
    "        test_acc.append(accuracy_score(y_test_np, y_pred_test_np))\n",
    "        test_pre.append(precision_score(y_test_np, y_pred_test_np))\n",
    "        test_rec.append(recall_score(y_test_np, y_pred_test_np))\n",
    "        test_f1.append(f1_score(y_test_np, y_pred_test_np))\n",
    "        test_auroc.append(roc_auc_score(y_test_np, y_pred_test_proba))\n",
    "\n",
    "print(\"=== Train Metrics ===\")\n",
    "print(\"Accuracy: \", np.mean(train_acc), \"±\", np.std(train_acc))\n",
    "print(\"Precision:\", np.mean(train_pre), \"±\", np.std(train_pre))\n",
    "print(\"Recall:   \", np.mean(train_rec), \"±\", np.std(train_rec))\n",
    "print(\"F1 Score: \", np.mean(train_f1), \"±\", np.std(train_f1))\n",
    "print(\"AUROC:    \", np.mean(train_auroc), \"±\", np.std(train_auroc))\n",
    "\n",
    "print(\"\\n=== Test Metrics ===\")\n",
    "print(\"Accuracy: \", np.mean(test_acc), \"±\", np.std(test_acc))\n",
    "print(\"Precision:\", np.mean(test_pre), \"±\", np.std(test_pre))\n",
    "print(\"Recall:   \", np.mean(test_rec), \"±\", np.std(test_rec))\n",
    "print(\"F1 Score: \", np.mean(test_f1), \"±\", np.std(test_f1))\n",
    "print(\"AUROC:    \", np.mean(test_auroc), \"±\", np.std(test_auroc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b9b9802c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Train Metrics ===\n",
      "Accuracy:  0.906201550387597 ± 0.017124590724321376\n",
      "Precision: 0.9006516924072007 ± 0.01514374518513446\n",
      "Recall:    0.8930752524988227 ± 0.02620045186961263\n",
      "F1 Score:  0.8968100767575832 ± 0.020685453788066428\n",
      "AUROC:     0.9475268312342742 ± 0.00498663624911052\n",
      "\n",
      "=== Test Metrics ===\n",
      "Accuracy:  0.8641975308641975 ± 0.023096650535641576\n",
      "Precision: 0.8695577391902605 ± 0.07032176204193617\n",
      "Recall:    0.8537486323200608 ± 0.03149826110403518\n",
      "F1 Score:  0.8585547426517777 ± 0.020439218877018543\n",
      "AUROC:     0.9086917725968733 ± 0.025147133463591206\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['A+', 'T+', 'N+'])\n",
    "y = df['N+']\n",
    "\n",
    "train_acc = []\n",
    "train_pre = []\n",
    "train_rec = []\n",
    "train_f1 = []\n",
    "train_auroc = []\n",
    "\n",
    "test_acc = []\n",
    "test_pre = []\n",
    "test_rec = []\n",
    "test_f1 = []\n",
    "test_auroc = []\n",
    "\n",
    "for i in range(0, 3):\n",
    "    rs = np.random.randint(0, 75)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=rs)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    y_train = torch.tensor(y_train.values, dtype=torch.float32).to(device).unsqueeze(1)\n",
    "    y_test = torch.tensor(y_test.values, dtype=torch.float32).to(device).unsqueeze(1)\n",
    "\n",
    "    model = SVM(X_train, y_train, kernel=gpytorch.kernels.RBFKernel()).to(device)\n",
    "    bhl = torchmetrics.classification.BinaryHingeLoss(squared=True).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "\n",
    "    # Training\n",
    "    for epoch in range(1, 101):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_train)\n",
    "        loss = bhl(output, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # EVAL: Train\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_train = model(X_train)\n",
    "        y_pred_train_labels = (y_pred_train > 0.5).float()\n",
    "        y_pred_train_np = y_pred_train_labels.cpu().numpy()\n",
    "        y_train_np = y_train.cpu().numpy()\n",
    "        y_pred_train_proba = y_pred_train.cpu().numpy()\n",
    "\n",
    "        train_acc.append(accuracy_score(y_train_np, y_pred_train_np))\n",
    "        train_pre.append(precision_score(y_train_np, y_pred_train_np))\n",
    "        train_rec.append(recall_score(y_train_np, y_pred_train_np))\n",
    "        train_f1.append(f1_score(y_train_np, y_pred_train_np))\n",
    "        train_auroc.append(roc_auc_score(y_train_np, y_pred_train_proba))\n",
    "\n",
    "    # EVAL: Test\n",
    "    with torch.no_grad():\n",
    "        y_pred_test = model(X_test)\n",
    "        y_pred_test_labels = (y_pred_test > 0.5).float()\n",
    "        y_pred_test_np = y_pred_test_labels.cpu().numpy()\n",
    "        y_test_np = y_test.cpu().numpy()\n",
    "        y_pred_test_proba = y_pred_test.cpu().numpy()\n",
    "\n",
    "        test_acc.append(accuracy_score(y_test_np, y_pred_test_np))\n",
    "        test_pre.append(precision_score(y_test_np, y_pred_test_np))\n",
    "        test_rec.append(recall_score(y_test_np, y_pred_test_np))\n",
    "        test_f1.append(f1_score(y_test_np, y_pred_test_np))\n",
    "        test_auroc.append(roc_auc_score(y_test_np, y_pred_test_proba))\n",
    "\n",
    "print(\"=== Train Metrics ===\")\n",
    "print(\"Accuracy: \", np.mean(train_acc), \"±\", np.std(train_acc))\n",
    "print(\"Precision:\", np.mean(train_pre), \"±\", np.std(train_pre))\n",
    "print(\"Recall:   \", np.mean(train_rec), \"±\", np.std(train_rec))\n",
    "print(\"F1 Score: \", np.mean(train_f1), \"±\", np.std(train_f1))\n",
    "print(\"AUROC:    \", np.mean(train_auroc), \"±\", np.std(train_auroc))\n",
    "\n",
    "print(\"\\n=== Test Metrics ===\")\n",
    "print(\"Accuracy: \", np.mean(test_acc), \"±\", np.std(test_acc))\n",
    "print(\"Precision:\", np.mean(test_pre), \"±\", np.std(test_pre))\n",
    "print(\"Recall:   \", np.mean(test_rec), \"±\", np.std(test_rec))\n",
    "print(\"F1 Score: \", np.mean(test_f1), \"±\", np.std(test_f1))\n",
    "print(\"AUROC:    \", np.mean(test_auroc), \"±\", np.std(test_auroc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d928a0af",
   "metadata": {},
   "source": [
    "# MTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dd357e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultitaskSVM(torch.nn.Module):\n",
    "    def __init__(self, features, targets, kernel: gpytorch.kernels.Kernel):\n",
    "        super(MultitaskSVM, self).__init__()\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        self.kernel = kernel\n",
    "        self.w = torch.nn.Parameter(torch.randn(features.shape[1], 3), requires_grad=True)\n",
    "        self.b = torch.nn.Parameter(torch.randn(1), requires_grad=True)\n",
    "        self.classifier = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        plane_output = x.matmul(self.w) + self.b\n",
    "        return self.classifier(plane_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "26ba93b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Train Metrics (A+ only) ===\n",
      "Accuracy:  0.8310077519379844 ± 0.00897351697890715\n",
      "Precision: 0.7982129416934667 ± 0.006184059800785192\n",
      "Recall:    0.8766647506844172 ± 0.007878076379859105\n",
      "F1 Score:  0.8355964812017436 ± 0.006685244658492608\n",
      "AUROC:     0.8739915532164341 ± 0.003912586734090038\n",
      "\n",
      "=== Test Metrics (A+ only) ===\n",
      "Accuracy:  0.8425925925925926 ± 0.026189140043946214\n",
      "Precision: 0.8249484878697242 ± 0.020051163941126878\n",
      "Recall:    0.8803034895233477 ± 0.009786796772523988\n",
      "F1 Score:  0.851660215221934 ± 0.014459247207377107\n",
      "AUROC:     0.867645058046015 ± 0.013579797395908493\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['A+', 'T+', 'N+'])\n",
    "y = df.filter(['A+', 'T+', 'N+'])\n",
    "\n",
    "train_acc, train_pre, train_rec, train_f1, train_auroc = [], [], [], [], []\n",
    "test_acc, test_pre, test_rec, test_f1, test_auroc = [], [], [], [], []\n",
    "\n",
    "X = df.drop(columns=['A+', 'T+', 'N+'])\n",
    "y = df[['A+', 'T+', 'N+']]\n",
    "\n",
    "for i in range(3):\n",
    "    rs = np.random.randint(0, 75)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=rs)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    y_train = torch.tensor(y_train.values, dtype=torch.float32).to(device)\n",
    "    y_test = torch.tensor(y_test.values, dtype=torch.float32).to(device)\n",
    "\n",
    "    model = MultitaskSVM(X_train, y_train, kernel=gpytorch.kernels.RBFKernel()).to(device)\n",
    "    bhl = torchmetrics.classification.BinaryHingeLoss(squared=True).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.061911627281932204, weight_decay=8.933152146862321e-05)\n",
    "\n",
    "    for epoch in range(100):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_train)\n",
    "        loss = bhl(output, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_train_all = model(X_train)\n",
    "        y_pred_train_prob = torch.sigmoid(y_pred_train_all[:, 0])\n",
    "        y_pred_train_labels = (y_pred_train_prob > 0.5).float()\n",
    "\n",
    "        y_train_np = y_train[:, 0].cpu().numpy()\n",
    "        y_pred_train_np = y_pred_train_labels.cpu().numpy()\n",
    "        y_pred_train_proba = y_pred_train_prob.cpu().numpy()\n",
    "\n",
    "        train_acc.append(accuracy_score(y_train_np, y_pred_train_np))\n",
    "        train_pre.append(precision_score(y_train_np, y_pred_train_np))\n",
    "        train_rec.append(recall_score(y_train_np, y_pred_train_np))\n",
    "        train_f1.append(f1_score(y_train_np, y_pred_train_np))\n",
    "        train_auroc.append(roc_auc_score(y_train_np, y_pred_train_proba))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred_test_all = model(X_test)\n",
    "        y_pred_test_prob = torch.sigmoid(y_pred_test_all[:, 0])\n",
    "        y_pred_test_labels = (y_pred_test_prob > 0.5).float()\n",
    "\n",
    "        y_test_np = y_test[:, 0].cpu().numpy()\n",
    "        y_pred_test_np = y_pred_test_labels.cpu().numpy()\n",
    "        y_pred_test_proba = y_pred_test_prob.cpu().numpy()\n",
    "\n",
    "        test_acc.append(accuracy_score(y_test_np, y_pred_test_np))\n",
    "        test_pre.append(precision_score(y_test_np, y_pred_test_np))\n",
    "        test_rec.append(recall_score(y_test_np, y_pred_test_np))\n",
    "        test_f1.append(f1_score(y_test_np, y_pred_test_np))\n",
    "        test_auroc.append(roc_auc_score(y_test_np, y_pred_test_proba))\n",
    "\n",
    "print(\"=== Train Metrics (A+ only) ===\")\n",
    "print(f\"Accuracy:  {np.mean(train_acc)} ± {np.std(train_acc)}\")\n",
    "print(f\"Precision: {np.mean(train_pre)} ± {np.std(train_pre)}\")\n",
    "print(f\"Recall:    {np.mean(train_rec)} ± {np.std(train_rec)}\")\n",
    "print(f\"F1 Score:  {np.mean(train_f1)} ± {np.std(train_f1)}\")\n",
    "print(f\"AUROC:     {np.mean(train_auroc)} ± {np.std(train_auroc)}\")\n",
    "\n",
    "print(\"\\n=== Test Metrics (A+ only) ===\")\n",
    "print(f\"Accuracy:  {np.mean(test_acc)} ± {np.std(test_acc)}\")\n",
    "print(f\"Precision: {np.mean(test_pre)} ± {np.std(test_pre)}\")\n",
    "print(f\"Recall:    {np.mean(test_rec)} ± {np.std(test_rec)}\")\n",
    "print(f\"F1 Score:  {np.mean(test_f1)} ± {np.std(test_f1)}\")\n",
    "print(f\"AUROC:     {np.mean(test_auroc)} ± {np.std(test_auroc)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bc59ecfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Train Metrics (T+ only) ===\n",
      "Accuracy:  0.841860465116279 ± 0.006846326252967328\n",
      "Precision: 0.8106826677159158 ± 0.010648550076435847\n",
      "Recall:    0.8804678016446493 ± 0.004302283007272975\n",
      "F1 Score:  0.8440792275198916 ± 0.005032863087160245\n",
      "AUROC:     0.8733227503205442 ± 0.006770690828057027\n",
      "\n",
      "=== Test Metrics (T+ only) ===\n",
      "Accuracy:  0.8487654320987654 ± 0.028622279307085476\n",
      "Precision: 0.8295734342017652 ± 0.018218613712946644\n",
      "Recall:    0.9013360646657477 ± 0.026152815149260034\n",
      "F1 Score:  0.8637687069934068 ± 0.017957695892248854\n",
      "AUROC:     0.8769443876026329 ± 0.025926167347265876\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['A+', 'T+', 'N+'])\n",
    "y = df.filter(['A+', 'T+', 'N+'])\n",
    "\n",
    "train_acc, train_pre, train_rec, train_f1, train_auroc = [], [], [], [], []\n",
    "test_acc, test_pre, test_rec, test_f1, test_auroc = [], [], [], [], []\n",
    "\n",
    "X = df.drop(columns=['A+', 'T+', 'N+'])\n",
    "y = df[['A+', 'T+', 'N+']]\n",
    "\n",
    "for i in range(3):\n",
    "    rs = np.random.randint(0, 75)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=rs)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    y_train = torch.tensor(y_train.values, dtype=torch.float32).to(device)\n",
    "    y_test = torch.tensor(y_test.values, dtype=torch.float32).to(device)\n",
    "\n",
    "    model = MultitaskSVM(X_train, y_train, kernel=gpytorch.kernels.RBFKernel()).to(device)\n",
    "    bhl = torchmetrics.classification.BinaryHingeLoss(squared=True).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.061911627281932204, weight_decay=8.933152146862321e-05)\n",
    "\n",
    "    for epoch in range(100):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_train)\n",
    "        loss = bhl(output, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_train_all = model(X_train)\n",
    "        y_pred_train_prob = torch.sigmoid(y_pred_train_all[:, 1])\n",
    "        y_pred_train_labels = (y_pred_train_prob > 0.5).float()\n",
    "\n",
    "        y_train_np = y_train[:, 0].cpu().numpy()\n",
    "        y_pred_train_np = y_pred_train_labels.cpu().numpy()\n",
    "        y_pred_train_proba = y_pred_train_prob.cpu().numpy()\n",
    "\n",
    "        train_acc.append(accuracy_score(y_train_np, y_pred_train_np))\n",
    "        train_pre.append(precision_score(y_train_np, y_pred_train_np))\n",
    "        train_rec.append(recall_score(y_train_np, y_pred_train_np))\n",
    "        train_f1.append(f1_score(y_train_np, y_pred_train_np))\n",
    "        train_auroc.append(roc_auc_score(y_train_np, y_pred_train_proba))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred_test_all = model(X_test)\n",
    "        y_pred_test_prob = torch.sigmoid(y_pred_test_all[:, 1])\n",
    "        y_pred_test_labels = (y_pred_test_prob > 0.5).float()\n",
    "\n",
    "        y_test_np = y_test[:, 0].cpu().numpy()\n",
    "        y_pred_test_np = y_pred_test_labels.cpu().numpy()\n",
    "        y_pred_test_proba = y_pred_test_prob.cpu().numpy()\n",
    "\n",
    "        test_acc.append(accuracy_score(y_test_np, y_pred_test_np))\n",
    "        test_pre.append(precision_score(y_test_np, y_pred_test_np))\n",
    "        test_rec.append(recall_score(y_test_np, y_pred_test_np))\n",
    "        test_f1.append(f1_score(y_test_np, y_pred_test_np))\n",
    "        test_auroc.append(roc_auc_score(y_test_np, y_pred_test_proba))\n",
    "\n",
    "print(\"=== Train Metrics (T+ only) ===\")\n",
    "print(f\"Accuracy:  {np.mean(train_acc)} ± {np.std(train_acc)}\")\n",
    "print(f\"Precision: {np.mean(train_pre)} ± {np.std(train_pre)}\")\n",
    "print(f\"Recall:    {np.mean(train_rec)} ± {np.std(train_rec)}\")\n",
    "print(f\"F1 Score:  {np.mean(train_f1)} ± {np.std(train_f1)}\")\n",
    "print(f\"AUROC:     {np.mean(train_auroc)} ± {np.std(train_auroc)}\")\n",
    "\n",
    "print(\"\\n=== Test Metrics (T+ only) ===\")\n",
    "print(f\"Accuracy:  {np.mean(test_acc)} ± {np.std(test_acc)}\")\n",
    "print(f\"Precision: {np.mean(test_pre)} ± {np.std(test_pre)}\")\n",
    "print(f\"Recall:    {np.mean(test_rec)} ± {np.std(test_rec)}\")\n",
    "print(f\"F1 Score:  {np.mean(test_f1)} ± {np.std(test_f1)}\")\n",
    "print(f\"AUROC:     {np.mean(test_auroc)} ± {np.std(test_auroc)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f9097d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Train Metrics (N+ only) ===\n",
      "Accuracy:  0.8248062015503876 ± 0.016149353996898954\n",
      "Precision: 0.798026448325551 ± 0.02271156721922992\n",
      "Recall:    0.8671624764161292 ± 0.011324381340577012\n",
      "F1 Score:  0.8309697479419936 ± 0.013757553415264058\n",
      "AUROC:     0.8660051403864929 ± 0.007577443607398803\n",
      "\n",
      "=== Test Metrics (N+ only) ===\n",
      "Accuracy:  0.8549382716049383 ± 0.008729713347982107\n",
      "Precision: 0.8110100860461958 ± 0.0426575846051556\n",
      "Recall:    0.9244073536526368 ± 0.05542254050543656\n",
      "F1 Score:  0.8612836438923396 ± 0.005855956780012828\n",
      "AUROC:     0.895397801883651 ± 0.02053242050444273\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['A+', 'T+', 'N+'])\n",
    "y = df.filter(['A+', 'T+', 'N+'])\n",
    "\n",
    "train_acc, train_pre, train_rec, train_f1, train_auroc = [], [], [], [], []\n",
    "test_acc, test_pre, test_rec, test_f1, test_auroc = [], [], [], [], []\n",
    "\n",
    "X = df.drop(columns=['A+', 'T+', 'N+'])\n",
    "y = df[['A+', 'T+', 'N+']]\n",
    "\n",
    "for i in range(3):\n",
    "    rs = np.random.randint(0, 75)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=rs)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    y_train = torch.tensor(y_train.values, dtype=torch.float32).to(device)\n",
    "    y_test = torch.tensor(y_test.values, dtype=torch.float32).to(device)\n",
    "\n",
    "    model = MultitaskSVM(X_train, y_train, kernel=gpytorch.kernels.RBFKernel()).to(device)\n",
    "    bhl = torchmetrics.classification.BinaryHingeLoss(squared=True).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.061911627281932204, weight_decay=8.933152146862321e-05)\n",
    "\n",
    "    for epoch in range(100):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_train)\n",
    "        loss = bhl(output, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_train_all = model(X_train)\n",
    "        y_pred_train_prob = torch.sigmoid(y_pred_train_all[:, 2])\n",
    "        y_pred_train_labels = (y_pred_train_prob > 0.5).float()\n",
    "\n",
    "        y_train_np = y_train[:, 0].cpu().numpy()\n",
    "        y_pred_train_np = y_pred_train_labels.cpu().numpy()\n",
    "        y_pred_train_proba = y_pred_train_prob.cpu().numpy()\n",
    "\n",
    "        train_acc.append(accuracy_score(y_train_np, y_pred_train_np))\n",
    "        train_pre.append(precision_score(y_train_np, y_pred_train_np))\n",
    "        train_rec.append(recall_score(y_train_np, y_pred_train_np))\n",
    "        train_f1.append(f1_score(y_train_np, y_pred_train_np))\n",
    "        train_auroc.append(roc_auc_score(y_train_np, y_pred_train_proba))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred_test_all = model(X_test)\n",
    "        y_pred_test_prob = torch.sigmoid(y_pred_test_all[:, 2])\n",
    "        y_pred_test_labels = (y_pred_test_prob > 0.5).float()\n",
    "\n",
    "        y_test_np = y_test[:, 0].cpu().numpy()\n",
    "        y_pred_test_np = y_pred_test_labels.cpu().numpy()\n",
    "        y_pred_test_proba = y_pred_test_prob.cpu().numpy()\n",
    "\n",
    "        test_acc.append(accuracy_score(y_test_np, y_pred_test_np))\n",
    "        test_pre.append(precision_score(y_test_np, y_pred_test_np))\n",
    "        test_rec.append(recall_score(y_test_np, y_pred_test_np))\n",
    "        test_f1.append(f1_score(y_test_np, y_pred_test_np))\n",
    "        test_auroc.append(roc_auc_score(y_test_np, y_pred_test_proba))\n",
    "\n",
    "print(\"=== Train Metrics (N+ only) ===\")\n",
    "print(f\"Accuracy:  {np.mean(train_acc)} ± {np.std(train_acc)}\")\n",
    "print(f\"Precision: {np.mean(train_pre)} ± {np.std(train_pre)}\")\n",
    "print(f\"Recall:    {np.mean(train_rec)} ± {np.std(train_rec)}\")\n",
    "print(f\"F1 Score:  {np.mean(train_f1)} ± {np.std(train_f1)}\")\n",
    "print(f\"AUROC:     {np.mean(train_auroc)} ± {np.std(train_auroc)}\")\n",
    "\n",
    "print(\"\\n=== Test Metrics (N+ only) ===\")\n",
    "print(f\"Accuracy:  {np.mean(test_acc)} ± {np.std(test_acc)}\")\n",
    "print(f\"Precision: {np.mean(test_pre)} ± {np.std(test_pre)}\")\n",
    "print(f\"Recall:    {np.mean(test_rec)} ± {np.std(test_rec)}\")\n",
    "print(f\"F1 Score:  {np.mean(test_f1)} ± {np.std(test_f1)}\")\n",
    "print(f\"AUROC:     {np.mean(test_auroc)} ± {np.std(test_auroc)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7486f67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6d666f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

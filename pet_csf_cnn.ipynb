{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-28T11:19:14.719079Z",
     "start_time": "2025-07-28T11:19:10.933040Z"
    }
   },
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "import os\n",
    "from nilearn.image import load_img\n",
    "import pandas as pd\n",
    "import gc\n",
    "from collections import OrderedDict\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "data_dir = 'data'\n",
    "pet_dir = \"data/ad_pet_huw\"\n",
    "os.makedirs('data/pet_csf', exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T11:19:17.874940Z",
     "start_time": "2025-07-28T11:19:14.949860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "files = {}\n",
    "for file in os.listdir(pet_dir):\n",
    "    if file.endswith(\".nii\"):\n",
    "        img = load_img(os.path.join(pet_dir, file))\n",
    "        patient_id = file.split(\".\")[0].removeprefix('AD_normalised_')\n",
    "        print(f'Processing patient: {patient_id}')\n",
    "        # Convert the image to a PyTorch tensor\n",
    "        torch_img = torch.tensor(img.get_fdata(), dtype=torch.float32)\n",
    "        files[patient_id] = torch_img"
   ],
   "id": "7cac866ca87c8e42",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing patient: 002_S_5018\n",
      "Processing patient: 003_S_4136\n",
      "Processing patient: 003_S_4152\n",
      "Processing patient: 003_S_4373\n",
      "Processing patient: 003_S_4892\n",
      "Processing patient: 003_S_5165\n",
      "Processing patient: 003_S_5187\n",
      "Processing patient: 005_S_4707\n",
      "Processing patient: 005_S_4910\n",
      "Processing patient: 005_S_5038\n",
      "Processing patient: 005_S_5119\n",
      "Processing patient: 006_S_4153\n",
      "Processing patient: 006_S_4192\n",
      "Processing patient: 006_S_4546\n",
      "Processing patient: 006_S_4867\n",
      "Processing patient: 007_S_4568\n",
      "Processing patient: 007_S_4637\n",
      "Processing patient: 007_S_4911\n",
      "Processing patient: 007_S_5196\n",
      "Processing patient: 009_S_5027\n",
      "Processing patient: 009_S_5037\n",
      "Processing patient: 009_S_5224\n",
      "Processing patient: 009_S_5252\n",
      "Processing patient: 011_S_4827\n",
      "Processing patient: 011_S_4845\n",
      "Processing patient: 011_S_4906\n",
      "Processing patient: 011_S_4912\n",
      "Processing patient: 011_S_4949\n",
      "Processing patient: 013_S_5071\n",
      "Processing patient: 014_S_4039\n",
      "Processing patient: 014_S_4615\n",
      "Processing patient: 016_S_4009\n",
      "Processing patient: 016_S_4353\n",
      "Processing patient: 016_S_4583\n",
      "Processing patient: 016_S_4591\n",
      "Processing patient: 016_S_4887\n",
      "Processing patient: 016_S_4963\n",
      "Processing patient: 016_S_5032\n",
      "Processing patient: 016_S_5057\n",
      "Processing patient: 016_S_5251\n",
      "Processing patient: 018_S_4696\n",
      "Processing patient: 018_S_5240\n",
      "Processing patient: 019_S_4252\n",
      "Processing patient: 019_S_4477\n",
      "Processing patient: 019_S_4549\n",
      "Processing patient: 019_S_5012\n",
      "Processing patient: 019_S_5019\n",
      "Processing patient: 021_S_4718\n",
      "Processing patient: 021_S_4924\n",
      "Processing patient: 023_S_4501\n",
      "Processing patient: 023_S_5120\n",
      "Processing patient: 023_S_5241\n",
      "Processing patient: 024_S_4223\n",
      "Processing patient: 024_S_4280\n",
      "Processing patient: 024_S_4905\n",
      "Processing patient: 024_S_5054\n",
      "Processing patient: 027_S_4801\n",
      "Processing patient: 027_S_4802\n",
      "Processing patient: 027_S_4938\n",
      "Processing patient: 027_S_4962\n",
      "Processing patient: 027_S_4964\n",
      "Processing patient: 029_S_4307\n",
      "Processing patient: 031_S_4024\n",
      "Processing patient: 032_S_4755\n",
      "Processing patient: 033_S_5013\n",
      "Processing patient: 033_S_5017\n",
      "Processing patient: 033_S_5087\n",
      "Processing patient: 035_S_4783\n",
      "Processing patient: 036_S_4740\n",
      "Processing patient: 036_S_4820\n",
      "Processing patient: 036_S_4894\n",
      "Processing patient: 036_S_5063\n",
      "Processing patient: 036_S_5112\n",
      "Processing patient: 036_S_5210\n",
      "Processing patient: 037_S_4001\n",
      "Processing patient: 037_S_4770\n",
      "Processing patient: 037_S_4879\n",
      "Processing patient: 037_S_5162\n",
      "Processing patient: 051_S_4980\n",
      "Processing patient: 051_S_5005\n",
      "Processing patient: 052_S_4959\n",
      "Processing patient: 052_S_5062\n",
      "Processing patient: 053_S_5070\n",
      "Processing patient: 053_S_5208\n",
      "Processing patient: 067_S_4728\n",
      "Processing patient: 067_S_5205\n",
      "Processing patient: 068_S_4859\n",
      "Processing patient: 068_S_4968\n",
      "Processing patient: 068_S_5146\n",
      "Processing patient: 070_S_4692\n",
      "Processing patient: 070_S_4719\n",
      "Processing patient: 073_S_4853\n",
      "Processing patient: 073_S_5016\n",
      "Processing patient: 073_S_5090\n",
      "Processing patient: 082_S_5029\n",
      "Processing patient: 082_S_5184\n",
      "Processing patient: 094_S_4089\n",
      "Processing patient: 094_S_4282\n",
      "Processing patient: 094_S_4737\n",
      "Processing patient: 098_S_4095\n",
      "Processing patient: 098_S_4201\n",
      "Processing patient: 098_S_4215\n",
      "Processing patient: 099_S_4994\n",
      "Processing patient: 100_S_5106\n",
      "Processing patient: 114_S_4379\n",
      "Processing patient: 116_S_4195\n",
      "Processing patient: 116_S_4209\n",
      "Processing patient: 116_S_4338\n",
      "Processing patient: 116_S_4625\n",
      "Processing patient: 116_S_4732\n",
      "Processing patient: 123_S_4526\n",
      "Processing patient: 126_S_4494\n",
      "Processing patient: 126_S_4686\n",
      "Processing patient: 127_S_4500\n",
      "Processing patient: 127_S_4940\n",
      "Processing patient: 127_S_4992\n",
      "Processing patient: 127_S_5028\n",
      "Processing patient: 127_S_5056\n",
      "Processing patient: 127_S_5058\n",
      "Processing patient: 127_S_5067\n",
      "Processing patient: 127_S_5095\n",
      "Processing patient: 128_S_4772\n",
      "Processing patient: 128_S_4774\n",
      "Processing patient: 128_S_4792\n",
      "Processing patient: 128_S_5123\n",
      "Processing patient: 130_S_4589\n",
      "Processing patient: 130_S_4641\n",
      "Processing patient: 130_S_4660\n",
      "Processing patient: 130_S_4730\n",
      "Processing patient: 130_S_4971\n",
      "Processing patient: 130_S_4982\n",
      "Processing patient: 130_S_4984\n",
      "Processing patient: 130_S_4990\n",
      "Processing patient: 130_S_4997\n",
      "Processing patient: 130_S_5006\n",
      "Processing patient: 130_S_5059\n",
      "Processing patient: 130_S_5231\n",
      "Processing patient: 131_S_5138\n",
      "Processing patient: 135_S_4657\n",
      "Processing patient: 135_S_4676\n",
      "Processing patient: 135_S_4863\n",
      "Processing patient: 135_S_4954\n",
      "Processing patient: 135_S_5015\n",
      "Processing patient: 135_S_5275\n",
      "Processing patient: 137_S_4211\n",
      "Processing patient: 137_S_4258\n",
      "Processing patient: 137_S_4672\n",
      "Processing patient: 137_S_4756\n",
      "Processing patient: 153_S_4172\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T11:19:18.447703Z",
     "start_time": "2025-07-28T11:19:17.941400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(os.path.join(data_dir, 'ADNIMERGE_19Jun2025.csv'))\n",
    "df['ABETA_bl'] = df['ABETA_bl'].astype(str).str.extract(r'(\\d+\\.?\\d*)').astype(float)\n",
    "df['PTAU_bl'] = df['PTAU_bl'].astype(str).str.extract(r'(\\d+\\.?\\d*)').astype(float)\n",
    "df['TAU_bl'] = df['TAU_bl'].astype(str).str.extract(r'(\\d+\\.?\\d*)').astype(float)\n",
    "df['tau_ab_ratio'] = df['TAU_bl'] / df['ABETA_bl']\n",
    "df['ptau_ab_ratio'] = df['PTAU_bl'] / df['ABETA_bl']\n",
    "df['A+'] = df['ABETA_bl'].apply(lambda x: 1 if x < 880 else 0)\n",
    "df['T+'] = df['ptau_ab_ratio'].apply(lambda x: 1 if x > 0.028 else 0)\n",
    "df['N+'] = df['tau_ab_ratio'].apply(lambda x: 1 if x > 0.33 else 0)\n",
    "df = df.filter(['PTID', 'A+', 'T+', 'N+'])\n",
    "df.head()"
   ],
   "id": "20ee4c9661f6bf15",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhruv Khanna\\AppData\\Local\\Temp\\ipykernel_19596\\4162410189.py:1: DtypeWarning: Columns (19,20,21,50,51,104,105,106) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(data_dir, 'ADNIMERGE_19Jun2025.csv'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         PTID  A+  T+  N+\n",
       "0  011_S_0002   0   0   0\n",
       "1  011_S_0003   1   1   0\n",
       "2  011_S_0003   1   1   0\n",
       "3  011_S_0003   1   1   0\n",
       "4  011_S_0003   1   1   0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PTID</th>\n",
       "      <th>A+</th>\n",
       "      <th>T+</th>\n",
       "      <th>N+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>011_S_0002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>011_S_0003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>011_S_0003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>011_S_0003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>011_S_0003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T11:19:18.618476Z",
     "start_time": "2025-07-28T11:19:18.596644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compute the number of common patients between the PET files and the df\n",
    "missing_patients = df[~df['PTID'].isin(files.keys())]\n",
    "print(f'Missing patients: {len(missing_patients)}')\n",
    "\n",
    "common_patients = df['PTID'].isin(files.keys())\n",
    "print(f'Common patients: {common_patients.sum()}')\n",
    "\n",
    "print(f'Total patients {len(files)}')"
   ],
   "id": "979b8a8399b39a42",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing patients: 15684\n",
      "Common patients: 737\n",
      "Total patients 149\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T11:19:19.606751Z",
     "start_time": "2025-07-28T11:19:18.883732Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Update the DataFrame to include a new column for the PET image data matched on PTID\n",
    "for patient in files:\n",
    "    img = files.get(patient)\n",
    "    df['PET_IMAGE'] = df['PTID'].map(files) # Insert the img data ino the 'PET_IMAGE' column in df for the corresponding PTID field"
   ],
   "id": "46d0f341e556b0c2",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T11:19:19.661613Z",
     "start_time": "2025-07-28T11:19:19.650400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print the PTID for the columns for which PET_IMAGE is not None\n",
    "print(f'Number of patients: {len(df)}')\n",
    "df.dropna(subset=['PET_IMAGE'], inplace=True)\n",
    "df.drop_duplicates(subset=['PTID'], inplace=True)\n",
    "print(f'Number of patients with PET images: {len(df)}')"
   ],
   "id": "1864341c11ea5d00",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patients: 16421\n",
      "Number of patients with PET images: 149\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T11:19:36.233522Z",
     "start_time": "2025-07-28T11:19:36.134517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PETDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        return image.unsqueeze(0), label  # Add channel dimension for CNN input\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'cpu'\n",
    "torch.cuda.empty_cache()\n",
    "print(f'Using device: {device}')"
   ],
   "id": "c810f1533b5202cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T11:19:38.360031Z",
     "start_time": "2025-07-28T11:19:38.328834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DeepPETModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepPETModel, self).__init__()\n",
    "        pass\n",
    "\n",
    "    def inheritance_test(self):\n",
    "        print(\"DeepPETModel inheritance test passed!\")\n",
    "\n",
    "    def input_gradient_hook(self, gradients):\n",
    "        \"\"\"\n",
    "        cature gradient with respect to input\n",
    "        \"\"\"\n",
    "\n",
    "        # print(\"triggered input gradient hook\")\n",
    "        self.input_gradient = gradients\n",
    "\n",
    "    def activation_gradient_hook(self, gradients):\n",
    "        \"\"\"\n",
    "        capture gradient with respect to activation maps\n",
    "        \"\"\"\n",
    "\n",
    "        # print(\"triggered activation gradient hook\")\n",
    "        self.activation_gradients = gradients\n",
    "\n",
    "    def get_activation_maps(self, x):\n",
    "        \"\"\"\n",
    "        return the activation maps of the last convolutional block\n",
    "        \"\"\"\n",
    "\n",
    "        return self.activation_maps\n",
    "\n",
    "    def get_input_gradient(self):\n",
    "        \"\"\"\n",
    "        retrieve gradient with respect to input\n",
    "        \"\"\"\n",
    "\n",
    "        return self.input_gradient\n",
    "\n",
    "    def get_activation_gradients(self):\n",
    "        \"\"\"\n",
    "        retrieve gradient with respect to activation maps\n",
    "        \"\"\"\n",
    "\n",
    "        return self.activation_gradients\n",
    "\n",
    "\n",
    "class PreActivationResBlock(torch.nn.Module):\n",
    "    def __init__(self, planes):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv3d(\n",
    "            planes, planes, kernel_size=3, stride=1, padding=1, bias=False\n",
    "        )\n",
    "        self.conv2 = torch.nn.Conv3d(\n",
    "            planes, planes, kernel_size=3, stride=1, padding=1, bias=False\n",
    "        )\n",
    "        self.bn1 = torch.nn.BatchNorm3d(planes)\n",
    "        self.bn2 = torch.nn.BatchNorm3d(planes)\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "        self.dropout = torch.nn.Dropout3d(p=0.25)\n",
    "\n",
    "    def preresidual_gradient_hook(self, gradients):\n",
    "        \"\"\"\n",
    "        cature gradient with respect to input\n",
    "        \"\"\"\n",
    "        self.preresidual_gradients = gradients\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        if (not self.training) and (x.requires_grad):\n",
    "            # print(f\"PreActivationResBlock: triggered gradient hook\")\n",
    "            h = x.register_hook(self.preresidual_gradient_hook)\n",
    "        self.preresidual_activation_maps = out.detach().clone()\n",
    "        out += x\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class DeepPETEncoder(DeepPETModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer0 = self._make_layer(1, 8, stride=1)\n",
    "        self.layer1 = self._make_layer(8, 16, stride=2)\n",
    "        self.layer2 = self._make_layer(16, 32, stride=2)\n",
    "        self.layer3 = self._make_layer(32, 64, stride=2)\n",
    "        self.layer4 = self._make_layer(64, 128, stride=2)\n",
    "\n",
    "        self.output = torch.nn.Sequential(\n",
    "            torch.nn.Dropout(p=0.50),\n",
    "            torch.nn.Linear(128, 1),\n",
    "        )\n",
    "\n",
    "        self.layers = [self.layer0, self.layer1, self.layer2, self.layer3, self.layer4]\n",
    "\n",
    "        self.input_gradient = None\n",
    "        self.gradients = None\n",
    "\n",
    "    def _make_layer(self, in_planes, out_planes, stride=1):\n",
    "\n",
    "        layers = [\n",
    "            torch.nn.Conv3d(\n",
    "                in_planes,\n",
    "                out_planes,\n",
    "                kernel_size=3,\n",
    "                stride=stride,\n",
    "                padding=1,\n",
    "                bias=False,\n",
    "            )\n",
    "        ]\n",
    "        layers.append(PreActivationResBlock(planes=out_planes))\n",
    "\n",
    "        return torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        if (not self.training) and (x.requires_grad):\n",
    "            h = x.register_hook(self.input_gradient_hook)\n",
    "\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        if (not self.training) and (x.requires_grad):\n",
    "            # print(f\"DeepPETEncoder: triggered gradient hook\")\n",
    "            h = x.register_hook(self.activation_gradient_hook)\n",
    "\n",
    "        # global average pooling 3d\n",
    "        x = x.mean(dim=(-3, -2, -1))\n",
    "        x = self.output(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class PreActivationResBlockGradCAM(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    GradCAM-compatible PreActivaitonResBlock\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, planes):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv3d(\n",
    "            planes, planes, kernel_size=3, stride=1, padding=1, bias=False\n",
    "        )\n",
    "        self.conv2 = torch.nn.Conv3d(\n",
    "            planes, planes, kernel_size=3, stride=1, padding=1, bias=False\n",
    "        )\n",
    "        self.bn1 = torch.nn.BatchNorm3d(planes)\n",
    "        self.bn2 = torch.nn.BatchNorm3d(planes)\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "        self.dropout = torch.nn.Dropout3d(p=0.25)\n",
    "\n",
    "    def preresidual_gradient_hook(self, gradients):\n",
    "        \"\"\"\n",
    "        cature gradient with respect to input\n",
    "        \"\"\"\n",
    "        self.preresidual_gradients = gradients\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        if (not self.training) and (x.requires_grad):\n",
    "            # print(f\"PreActivationResBlock: triggered gradient hook\")\n",
    "            h = x.register_hook(self.preresidual_gradient_hook)\n",
    "        self.preresidual_activation_maps = out.detach().clone()\n",
    "        out += x\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class DeepPETEncoderGradCAM(DeepPETModel):\n",
    "    \"\"\"\n",
    "    GradCAM-compatible DeepPETEncoder\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_layer0 = self._make_conv_layer(1, 8, stride=1)\n",
    "        self.conv_layer1 = self._make_conv_layer(8, 16, stride=2)\n",
    "        self.conv_layer2 = self._make_conv_layer(16, 32, stride=2)\n",
    "        self.conv_layer3 = self._make_conv_layer(32, 64, stride=2)\n",
    "        self.conv_layer4 = self._make_conv_layer(64, 128, stride=2)\n",
    "\n",
    "        self.preres_block0 = self._make_preres_block(8)\n",
    "        self.preres_block1 = self._make_preres_block(16)\n",
    "        self.preres_block2 = self._make_preres_block(32)\n",
    "        self.preres_block3 = self._make_preres_block(64)\n",
    "        self.preres_block4 = self._make_preres_block(128)\n",
    "\n",
    "        self.output = torch.nn.Sequential(\n",
    "            torch.nn.Dropout(p=0.50),\n",
    "            torch.nn.Linear(128, 1),\n",
    "        )\n",
    "\n",
    "        self.input_gradient = None\n",
    "        self.gradients = None\n",
    "\n",
    "        # # Freeze the encoder layers and add a classifier head\n",
    "        # for param in self.parameters():\n",
    "        #     param.requires_grad = False\n",
    "\n",
    "        self.classifier_head = torch.nn.Sigmoid()\n",
    "\n",
    "    def _make_conv_layer(self, in_planes, out_planes, stride=1):\n",
    "\n",
    "        return torch.nn.Conv3d(\n",
    "            in_planes,\n",
    "            out_planes,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "    def _make_preres_block(self, planes):\n",
    "\n",
    "        return PreActivationResBlock(planes=planes)\n",
    "\n",
    "    def forward(self, x0):\n",
    "\n",
    "        if (not self.training) and (x0.requires_grad):\n",
    "            h = x0.register_hook(self.input_gradient_hook)\n",
    "\n",
    "        x0 = self.conv_layer0(x0)\n",
    "        x1 = self.preres_block0(x0)\n",
    "        x1 = x1.add(x0)\n",
    "\n",
    "        x1 = self.conv_layer1(x1)\n",
    "        x2 = self.preres_block1(x1)\n",
    "        x2 = x2.add(x1)\n",
    "\n",
    "        x2 = self.conv_layer2(x2)\n",
    "        x3 = self.preres_block2(x2)\n",
    "        x3 = x3.add(x2)\n",
    "\n",
    "        x3 = self.conv_layer3(x3)\n",
    "        x4 = self.preres_block3(x3)\n",
    "        x4 = x4.add(x3)\n",
    "\n",
    "        x4 = self.conv_layer4(x4)\n",
    "        x5 = self.preres_block4(x4)\n",
    "        if (not self.training) and (x5.requires_grad):\n",
    "            # print(f\"DeepPETEncoder: triggered gradient hook\")\n",
    "            h = x5.register_hook(self.activation_gradient_hook)\n",
    "        # make a copy of tensor and store as activation maps\n",
    "        self.activation_maps = x5.detach().clone()\n",
    "        x5 = x5.add(x4)\n",
    "\n",
    "        # global average pooling 3d\n",
    "        x5 = x5.mean(dim=(-3, -2, -1))\n",
    "        x5 = self.output(x5)\n",
    "\n",
    "        # return x5\n",
    "        return self.classifier_head(x5)\n",
    "\n",
    "\n",
    "class _DenseLayer(torch.nn.Sequential):\n",
    "    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate):\n",
    "        super().__init__()\n",
    "        self.add_module(\"norm1\", torch.nn.BatchNorm3d(num_input_features))\n",
    "        self.add_module(\"relu1\", torch.nn.ReLU(inplace=True))\n",
    "        self.add_module(\n",
    "            \"conv1\",\n",
    "            torch.nn.Conv3d(\n",
    "                num_input_features,\n",
    "                bn_size * growth_rate,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                bias=False,\n",
    "            ),\n",
    "        )\n",
    "        self.add_module(\"norm2\", torch.nn.BatchNorm3d(bn_size * growth_rate))\n",
    "        self.add_module(\"relu2\", torch.nn.ReLU(inplace=True))\n",
    "        self.add_module(\n",
    "            \"conv2\",\n",
    "            torch.nn.Conv3d(\n",
    "                bn_size * growth_rate,\n",
    "                growth_rate,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "                bias=False,\n",
    "            ),\n",
    "        )\n",
    "        self.drop_rate = drop_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        new_features = super().forward(x)\n",
    "        if self.drop_rate > 0:\n",
    "            new_features = torch.nn.functional.dropout(\n",
    "                new_features, p=self.drop_rate, training=self.training\n",
    "            )\n",
    "        return torch.cat([x, new_features], 1)\n",
    "\n",
    "\n",
    "class _DenseBlock(torch.nn.Sequential):\n",
    "    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate):\n",
    "        super().__init__()\n",
    "        for i in range(num_layers):\n",
    "            layer = _DenseLayer(\n",
    "                num_input_features + i * growth_rate, growth_rate, bn_size, drop_rate\n",
    "            )\n",
    "            self.add_module(f\"denselayer{(i + 1)}\", layer)\n",
    "\n",
    "\n",
    "class _Transition(torch.nn.Sequential):\n",
    "    def __init__(self, num_input_features, num_output_features):\n",
    "        super().__init__()\n",
    "        self.add_module(\"norm\", torch.nn.BatchNorm3d(num_input_features))\n",
    "        self.add_module(\"relu\", torch.nn.ReLU(inplace=True))\n",
    "        self.add_module(\n",
    "            \"conv\",\n",
    "            torch.nn.Conv3d(\n",
    "                num_input_features,\n",
    "                num_output_features,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                bias=False,\n",
    "            ),\n",
    "        )\n",
    "        self.add_module(\"pool\", torch.nn.AvgPool3d(kernel_size=2, stride=2))\n",
    "\n",
    "\n",
    "class DeepPETDenseNetClassifier(torch.nn.Module):\n",
    "    \"\"\"Densenet-BC model class\n",
    "    Args:\n",
    "        growth_rate (int) - how many filters to add each layer (k in paper)\n",
    "        block_config (list of 4 ints) - how many layers in each pooling block\n",
    "        bn_size (int) - multiplicative factor for number of bottle neck layers\n",
    "          (i.e. bn_size * k features in the bottleneck layer)\n",
    "        drop_rate (float) - dropout rate after each dense layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        no_max_pool=False,\n",
    "        growth_rate=16,\n",
    "        block_config=(3, 3, 3, 3),\n",
    "        bn_size=4,\n",
    "        drop_rate=0.25,\n",
    "    ):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # First convolution\n",
    "        self.features = [\n",
    "            (\n",
    "                \"conv1\",\n",
    "                torch.nn.Conv3d(\n",
    "                    1,\n",
    "                    8,\n",
    "                    kernel_size=5,\n",
    "                    stride=2,\n",
    "                    padding=2,\n",
    "                    bias=False,\n",
    "                ),\n",
    "            ),\n",
    "            (\"norm1\", torch.nn.BatchNorm3d(8)),\n",
    "            (\"relu1\", torch.nn.ReLU(inplace=True)),\n",
    "        ]\n",
    "        if not no_max_pool:\n",
    "            self.features.append(\n",
    "                (\"pool1\", torch.nn.MaxPool3d(kernel_size=3, stride=2, padding=1))\n",
    "            )\n",
    "        self.features = torch.nn.Sequential(OrderedDict(self.features))\n",
    "\n",
    "        # Each denseblock\n",
    "        num_features = 8\n",
    "        for i, num_layers in enumerate(block_config):\n",
    "            block = _DenseBlock(\n",
    "                num_layers=num_layers,\n",
    "                num_input_features=num_features,\n",
    "                bn_size=bn_size,\n",
    "                growth_rate=growth_rate,\n",
    "                drop_rate=drop_rate,\n",
    "            )\n",
    "            self.features.add_module(f\"denseblock{(i + 1)}\", block)\n",
    "            num_features = num_features + num_layers * growth_rate\n",
    "            if i != len(block_config) - 1:\n",
    "                trans = _Transition(\n",
    "                    num_input_features=num_features,\n",
    "                    num_output_features=num_features // 2,\n",
    "                )\n",
    "                self.features.add_module(f\"transition{(i + 1)}\", trans)\n",
    "                num_features = num_features // 2\n",
    "\n",
    "        # final batch norm\n",
    "        self.features.add_module(\"norm5\", torch.nn.BatchNorm3d(num_features))\n",
    "        # final dense layer\n",
    "        self.classifier = torch.nn.Linear(num_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.features(x)\n",
    "        out = torch.nn.functional.adaptive_avg_pool3d(features, output_size=(1, 1, 1)).view(\n",
    "            features.size(0), -1\n",
    "        )\n",
    "        out = self.classifier(out)\n",
    "        return out"
   ],
   "id": "1a9a059d5cc8bed6",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Predict A+",
   "id": "72c962da533ff75a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T11:19:40.953501Z",
     "start_time": "2025-07-28T11:19:40.946750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Select PET_IMAGE and A+ from df\n",
    "X = df['PET_IMAGE'].tolist()  # This will be a list of torch.Tensor objects\n",
    "y = df['A+'].values     # This will be a numpy array of labels\n",
    "\n",
    "print(f'X length: {len(X)}, PET image shape: {X[0].shape}, y shape: {y.shape}')"
   ],
   "id": "4c677f9417bf50e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X length: 149, PET image shape: torch.Size([101, 116, 96]), y shape: (149,)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T11:19:42.421805Z",
     "start_time": "2025-07-28T11:19:42.402854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)\n",
    "print(f'Train X length: {len(X_train)}, Test X length: {len(X_test)} with shapes {X_train[0].shape}, {X_test[0].shape}')\n",
    "print(f'Train y shape: {y_train.shape}, Test y shape: {y_test.shape}')"
   ],
   "id": "305cf6b0e2deb97b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X length: 119, Test X length: 30 with shapes torch.Size([101, 116, 96]), torch.Size([101, 116, 96])\n",
      "Train y shape: (119,), Test y shape: (30,)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T11:19:44.995655Z",
     "start_time": "2025-07-28T11:19:43.657928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the train and test sets\n",
    "torch.save(X_train, 'data/pet_csf/X_train_aplus.pt')\n",
    "torch.save(y_train, 'data/pet_csf/y_train_aplus.pt')\n",
    "torch.save(X_test, 'data/pet_csf/X_test_aplus.pt')\n",
    "torch.save(y_test, 'data/pet_csf/y_test_aplus.pt')"
   ],
   "id": "bffb1d5a63cf3771",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T11:32:17.725717Z",
     "start_time": "2025-07-28T11:32:16.527275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train = torch.load('data/pet_csf/X_train_aplus.pt', weights_only=False)\n",
    "X_test = torch.load('data/pet_csf/X_test_aplus.pt', weights_only=False)\n",
    "y_train = torch.load('data/pet_csf/y_train_aplus.pt', weights_only=False)\n",
    "y_test = torch.load('data/pet_csf/y_test_aplus.pt', weights_only=False)"
   ],
   "id": "1d38ab7dc92e2b01",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T11:32:19.471468Z",
     "start_time": "2025-07-28T11:32:19.051832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 2\n",
    "model = DeepPETEncoderGradCAM()\n",
    "model.load_state_dict(torch.load('weights/deeppet.pth', weights_only=True)['model'])\n",
    "model.to(device)"
   ],
   "id": "3f0f9078fc74a814",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepPETEncoderGradCAM(\n",
       "  (conv_layer0): Conv3d(1, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "  (conv_layer1): Conv3d(8, 16, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "  (conv_layer2): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "  (conv_layer3): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "  (conv_layer4): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "  (preres_block0): PreActivationResBlock(\n",
       "    (conv1): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (conv2): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (bn1): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (dropout): Dropout3d(p=0.25, inplace=False)\n",
       "  )\n",
       "  (preres_block1): PreActivationResBlock(\n",
       "    (conv1): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (conv2): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (bn1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (dropout): Dropout3d(p=0.25, inplace=False)\n",
       "  )\n",
       "  (preres_block2): PreActivationResBlock(\n",
       "    (conv1): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (conv2): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (bn1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (dropout): Dropout3d(p=0.25, inplace=False)\n",
       "  )\n",
       "  (preres_block3): PreActivationResBlock(\n",
       "    (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (dropout): Dropout3d(p=0.25, inplace=False)\n",
       "  )\n",
       "  (preres_block4): PreActivationResBlock(\n",
       "    (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (dropout): Dropout3d(p=0.25, inplace=False)\n",
       "  )\n",
       "  (output): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       "  (classifier_head): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Test the pretrained model before tuning",
   "id": "54206d03ede8f6ae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T11:21:43.304429Z",
     "start_time": "2025-07-28T11:21:27.565169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compute the accuracy on the train set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    train_dataset = PETDataset(X_train, y_train)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    y_pred_train = []\n",
    "    y_true_train = []\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
    "        outputs = model(inputs)\n",
    "        y_pred_train.extend(outputs.cpu().numpy())\n",
    "        y_true_train.extend(labels.cpu().numpy())\n",
    "    y_pred_train = (torch.tensor(\n",
    "        y_pred_train) > 0.5).float().numpy()  # Convert probabilities to binary predictions\n",
    "    y_true_train = torch.tensor(y_true_train).numpy()\n",
    "    train_accuracy = accuracy_score(y_true_train, y_pred_train)\n",
    "    train_f1 = f1_score(y_true_train, y_pred_train)\n",
    "    train_roc_auc = roc_auc_score(y_true_train, y_pred_train)\n",
    "    print(\n",
    "        f'Train Accuracy: {train_accuracy:.4f}, Train F1 Score: {train_f1:.4f}, Train ROC AUC: {train_roc_auc:.4f}')"
   ],
   "id": "97f3b9142607852b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8151, Train F1 Score: 0.8830, Train ROC AUC: 0.6958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhruv Khanna\\AppData\\Local\\Temp\\ipykernel_19596\\3392771040.py:14: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:257.)\n",
      "  y_pred_train = (torch.tensor(\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T11:22:22.655191Z",
     "start_time": "2025-07-28T11:22:19.806334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compute the accuracy on the test set\n",
    "with torch.no_grad():\n",
    "    test_dataset = PETDataset(X_test, y_test)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    y_pred_test = []\n",
    "    y_true_test = []\n",
    "\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
    "        outputs = model(inputs)\n",
    "        y_pred_test.extend(outputs.cpu().numpy())\n",
    "        y_true_test.extend(labels.cpu().numpy())\n",
    "    y_pred_test = (torch.tensor(\n",
    "        y_pred_test) > 0.5).float().numpy()  # Convert probabilities to binary predictions\n",
    "    y_true_test = torch.tensor(y_true_test).numpy()\n",
    "    test_accuracy = accuracy_score(y_true_test, y_pred_test)\n",
    "    test_f1 = f1_score(y_true_test, y_pred_test)\n",
    "    test_roc_auc = roc_auc_score(y_true_test, y_pred_test)\n",
    "    print(\n",
    "        f'Test Accuracy: {test_accuracy:.4f}, Test F1 Score: {test_f1:.4f}, Test ROC AUC: {test_roc_auc:.4f}')"
   ],
   "id": "7fc53e9150ec6ec1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8667, Test F1 Score: 0.9231, Test ROC AUC: 0.6800\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Tune the pretrained model",
   "id": "8c3b9cd5926cc08b"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-07-28T11:42:20.710270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs = torch.stack([torch.unsqueeze(img, 0) for img in X_train], dim=0)  # Add channel dimension\n",
    "labels = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)  # Convert labels to float and add a channel dimension\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 100\n",
    "train_losses = []\n",
    "\n",
    "batch_size = 2  # Adjust based on your GPU memory\n",
    "train_dataset = PETDataset(X_train, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "total_batches = len(train_loader)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    batch_counter = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
    "        batch_counter += 1\n",
    "        print(f'Processing batch {batch_counter}/{total_batches} of epoch {epoch}')\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        # print(f'Output shape: {outputs.shape}, Labels shape: {labels.shape}')\n",
    "        # print(f'Output: {outputs[:5]}, Labels: {labels[:5]}')\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "        # Save the best model based on loss\n",
    "        if loss.item() < min(train_losses, default=float('inf')):\n",
    "            torch.save(model.state_dict(), 'weights/best_deeppet_csf_tuned_aplus.pth')\n",
    "    del inputs, labels, outputs  # Clear variables to free memory\n",
    "    torch.cuda.empty_cache()  # Clear GPU memory after each epoch\n",
    "    gc.collect()  # Collect garbage to free up memory\n",
    "\n",
    "    print(f'Epoch [{epoch}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "torch.save(model.state_dict(), 'weights/deeppet_csf_tuned_aplus.pth')"
   ],
   "id": "fef98228120aec6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1/60 of epoch 1\n",
      "Processing batch 2/60 of epoch 1\n",
      "Processing batch 3/60 of epoch 1\n",
      "Processing batch 4/60 of epoch 1\n",
      "Processing batch 5/60 of epoch 1\n",
      "Processing batch 6/60 of epoch 1\n",
      "Processing batch 7/60 of epoch 1\n",
      "Processing batch 8/60 of epoch 1\n",
      "Processing batch 9/60 of epoch 1\n",
      "Processing batch 10/60 of epoch 1\n",
      "Processing batch 11/60 of epoch 1\n",
      "Processing batch 12/60 of epoch 1\n",
      "Processing batch 13/60 of epoch 1\n",
      "Processing batch 14/60 of epoch 1\n",
      "Processing batch 15/60 of epoch 1\n",
      "Processing batch 16/60 of epoch 1\n",
      "Processing batch 17/60 of epoch 1\n",
      "Processing batch 18/60 of epoch 1\n",
      "Processing batch 19/60 of epoch 1\n",
      "Processing batch 20/60 of epoch 1\n",
      "Processing batch 21/60 of epoch 1\n",
      "Processing batch 22/60 of epoch 1\n",
      "Processing batch 23/60 of epoch 1\n",
      "Processing batch 24/60 of epoch 1\n",
      "Processing batch 25/60 of epoch 1\n",
      "Processing batch 26/60 of epoch 1\n",
      "Processing batch 27/60 of epoch 1\n",
      "Processing batch 28/60 of epoch 1\n",
      "Processing batch 29/60 of epoch 1\n",
      "Processing batch 30/60 of epoch 1\n",
      "Processing batch 31/60 of epoch 1\n",
      "Processing batch 32/60 of epoch 1\n",
      "Processing batch 33/60 of epoch 1\n",
      "Processing batch 34/60 of epoch 1\n",
      "Processing batch 35/60 of epoch 1\n",
      "Processing batch 36/60 of epoch 1\n",
      "Processing batch 37/60 of epoch 1\n",
      "Processing batch 38/60 of epoch 1\n",
      "Processing batch 39/60 of epoch 1\n",
      "Processing batch 40/60 of epoch 1\n",
      "Processing batch 41/60 of epoch 1\n",
      "Processing batch 42/60 of epoch 1\n",
      "Processing batch 43/60 of epoch 1\n",
      "Processing batch 44/60 of epoch 1\n",
      "Processing batch 45/60 of epoch 1\n",
      "Processing batch 46/60 of epoch 1\n",
      "Processing batch 47/60 of epoch 1\n",
      "Processing batch 48/60 of epoch 1\n",
      "Processing batch 49/60 of epoch 1\n",
      "Processing batch 50/60 of epoch 1\n",
      "Processing batch 51/60 of epoch 1\n",
      "Processing batch 52/60 of epoch 1\n",
      "Processing batch 53/60 of epoch 1\n",
      "Processing batch 54/60 of epoch 1\n",
      "Processing batch 55/60 of epoch 1\n",
      "Processing batch 56/60 of epoch 1\n",
      "Processing batch 57/60 of epoch 1\n",
      "Processing batch 58/60 of epoch 1\n",
      "Processing batch 59/60 of epoch 1\n",
      "Processing batch 60/60 of epoch 1\n",
      "Epoch [1/100], Loss: 100.0000\n",
      "Processing batch 1/60 of epoch 2\n",
      "Processing batch 2/60 of epoch 2\n",
      "Processing batch 3/60 of epoch 2\n",
      "Processing batch 4/60 of epoch 2\n",
      "Processing batch 5/60 of epoch 2\n",
      "Processing batch 6/60 of epoch 2\n",
      "Processing batch 7/60 of epoch 2\n",
      "Processing batch 8/60 of epoch 2\n",
      "Processing batch 9/60 of epoch 2\n",
      "Processing batch 10/60 of epoch 2\n",
      "Processing batch 11/60 of epoch 2\n",
      "Processing batch 12/60 of epoch 2\n",
      "Processing batch 13/60 of epoch 2\n",
      "Processing batch 14/60 of epoch 2\n",
      "Processing batch 15/60 of epoch 2\n",
      "Processing batch 16/60 of epoch 2\n",
      "Processing batch 17/60 of epoch 2\n",
      "Processing batch 18/60 of epoch 2\n",
      "Processing batch 19/60 of epoch 2\n",
      "Processing batch 20/60 of epoch 2\n",
      "Processing batch 21/60 of epoch 2\n",
      "Processing batch 22/60 of epoch 2\n",
      "Processing batch 23/60 of epoch 2\n",
      "Processing batch 24/60 of epoch 2\n",
      "Processing batch 25/60 of epoch 2\n",
      "Processing batch 26/60 of epoch 2\n",
      "Processing batch 27/60 of epoch 2\n",
      "Processing batch 28/60 of epoch 2\n",
      "Processing batch 29/60 of epoch 2\n",
      "Processing batch 30/60 of epoch 2\n",
      "Processing batch 31/60 of epoch 2\n",
      "Processing batch 32/60 of epoch 2\n",
      "Processing batch 33/60 of epoch 2\n",
      "Processing batch 34/60 of epoch 2\n",
      "Processing batch 35/60 of epoch 2\n",
      "Processing batch 36/60 of epoch 2\n",
      "Processing batch 37/60 of epoch 2\n",
      "Processing batch 38/60 of epoch 2\n",
      "Processing batch 39/60 of epoch 2\n",
      "Processing batch 40/60 of epoch 2\n",
      "Processing batch 41/60 of epoch 2\n",
      "Processing batch 42/60 of epoch 2\n",
      "Processing batch 43/60 of epoch 2\n",
      "Processing batch 44/60 of epoch 2\n",
      "Processing batch 45/60 of epoch 2\n",
      "Processing batch 46/60 of epoch 2\n",
      "Processing batch 47/60 of epoch 2\n",
      "Processing batch 48/60 of epoch 2\n",
      "Processing batch 49/60 of epoch 2\n",
      "Processing batch 50/60 of epoch 2\n",
      "Processing batch 51/60 of epoch 2\n",
      "Processing batch 52/60 of epoch 2\n",
      "Processing batch 53/60 of epoch 2\n",
      "Processing batch 54/60 of epoch 2\n",
      "Processing batch 55/60 of epoch 2\n",
      "Processing batch 56/60 of epoch 2\n",
      "Processing batch 57/60 of epoch 2\n",
      "Processing batch 58/60 of epoch 2\n",
      "Processing batch 59/60 of epoch 2\n",
      "Processing batch 60/60 of epoch 2\n",
      "Epoch [2/100], Loss: 100.0000\n",
      "Processing batch 1/60 of epoch 3\n",
      "Processing batch 2/60 of epoch 3\n",
      "Processing batch 3/60 of epoch 3\n",
      "Processing batch 4/60 of epoch 3\n",
      "Processing batch 5/60 of epoch 3\n",
      "Processing batch 6/60 of epoch 3\n",
      "Processing batch 7/60 of epoch 3\n",
      "Processing batch 8/60 of epoch 3\n",
      "Processing batch 9/60 of epoch 3\n",
      "Processing batch 10/60 of epoch 3\n",
      "Processing batch 11/60 of epoch 3\n",
      "Processing batch 12/60 of epoch 3\n",
      "Processing batch 13/60 of epoch 3\n",
      "Processing batch 14/60 of epoch 3\n",
      "Processing batch 15/60 of epoch 3\n",
      "Processing batch 16/60 of epoch 3\n",
      "Processing batch 17/60 of epoch 3\n",
      "Processing batch 18/60 of epoch 3\n",
      "Processing batch 19/60 of epoch 3\n",
      "Processing batch 20/60 of epoch 3\n",
      "Processing batch 21/60 of epoch 3\n",
      "Processing batch 22/60 of epoch 3\n",
      "Processing batch 23/60 of epoch 3\n",
      "Processing batch 24/60 of epoch 3\n",
      "Processing batch 25/60 of epoch 3\n",
      "Processing batch 26/60 of epoch 3\n",
      "Processing batch 27/60 of epoch 3\n",
      "Processing batch 28/60 of epoch 3\n",
      "Processing batch 29/60 of epoch 3\n",
      "Processing batch 30/60 of epoch 3\n",
      "Processing batch 31/60 of epoch 3\n",
      "Processing batch 32/60 of epoch 3\n",
      "Processing batch 33/60 of epoch 3\n",
      "Processing batch 34/60 of epoch 3\n",
      "Processing batch 35/60 of epoch 3\n",
      "Processing batch 36/60 of epoch 3\n",
      "Processing batch 37/60 of epoch 3\n",
      "Processing batch 38/60 of epoch 3\n",
      "Processing batch 39/60 of epoch 3\n",
      "Processing batch 40/60 of epoch 3\n",
      "Processing batch 41/60 of epoch 3\n",
      "Processing batch 42/60 of epoch 3\n",
      "Processing batch 43/60 of epoch 3\n",
      "Processing batch 44/60 of epoch 3\n",
      "Processing batch 45/60 of epoch 3\n",
      "Processing batch 46/60 of epoch 3\n",
      "Processing batch 47/60 of epoch 3\n",
      "Processing batch 48/60 of epoch 3\n",
      "Processing batch 49/60 of epoch 3\n",
      "Processing batch 50/60 of epoch 3\n",
      "Processing batch 51/60 of epoch 3\n",
      "Processing batch 52/60 of epoch 3\n",
      "Processing batch 53/60 of epoch 3\n",
      "Processing batch 54/60 of epoch 3\n",
      "Processing batch 55/60 of epoch 3\n",
      "Processing batch 56/60 of epoch 3\n",
      "Processing batch 57/60 of epoch 3\n",
      "Processing batch 58/60 of epoch 3\n",
      "Processing batch 59/60 of epoch 3\n",
      "Processing batch 60/60 of epoch 3\n",
      "Epoch [3/100], Loss: 0.0000\n",
      "Processing batch 1/60 of epoch 4\n",
      "Processing batch 2/60 of epoch 4\n",
      "Processing batch 3/60 of epoch 4\n",
      "Processing batch 4/60 of epoch 4\n",
      "Processing batch 5/60 of epoch 4\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Compute the accuracy on the train set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    train_dataset = PETDataset(X_train, y_train)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    y_pred_train = []\n",
    "    y_true_train = []\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
    "        outputs = model(inputs)\n",
    "        y_pred_train.extend(outputs.cpu().numpy())\n",
    "        y_true_train.extend(labels.cpu().numpy())\n",
    "    y_pred_train = (torch.tensor(\n",
    "        y_pred_train) > 0.5).float().numpy()  # Convert probabilities to binary predictions\n",
    "    y_true_train = torch.tensor(y_true_train).numpy()\n",
    "    train_accuracy = accuracy_score(y_true_train, y_pred_train)\n",
    "    train_f1 = f1_score(y_true_train, y_pred_train)\n",
    "    train_roc_auc = roc_auc_score(y_true_train, y_pred_train)\n",
    "    print(\n",
    "        f'Train Accuracy: {train_accuracy:.4f}, Train F1 Score: {train_f1:.4f}, Train ROC AUC: {train_roc_auc:.4f}')"
   ],
   "id": "3aa4f5916d3108af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Compute the accuracy on the test set\n",
    "with torch.no_grad():\n",
    "    test_dataset = PETDataset(X_test, y_test)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    y_pred_test = []\n",
    "    y_true_test = []\n",
    "\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
    "        outputs = model(inputs)\n",
    "        y_pred_test.extend(outputs.cpu().numpy())\n",
    "        y_true_test.extend(labels.cpu().numpy())\n",
    "    y_pred_test = (torch.tensor(\n",
    "        y_pred_test) > 0.5).float().numpy()  # Convert probabilities to binary predictions\n",
    "    y_true_test = torch.tensor(y_true_test).numpy()\n",
    "    test_accuracy = accuracy_score(y_true_test, y_pred_test)\n",
    "    test_f1 = f1_score(y_true_test, y_pred_test)\n",
    "    test_roc_auc = roc_auc_score(y_true_test, y_pred_test)\n",
    "    print(\n",
    "        f'Test Accuracy: {test_accuracy:.4f}, Test F1 Score: {test_f1:.4f}, Test ROC AUC: {test_roc_auc:.4f}')"
   ],
   "id": "94deccc453116c59"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Predict T+",
   "id": "3a1d3e2d6f2dbd05"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T11:30:45.918972Z",
     "start_time": "2025-07-28T11:30:45.911187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Select PET_IMAGE and T+ from df\n",
    "X = df['PET_IMAGE'].tolist()  # This will be a list of torch.Tensor objects\n",
    "y = df['T+'].values     # This will be a numpy array of labels\n",
    "\n",
    "print(f'X length: {len(X)}, PET image shape: {X[0].shape}, y shape: {y.shape}')"
   ],
   "id": "fd2a74b248200a61",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X length: 149, PET image shape: torch.Size([101, 116, 96]), y shape: (149,)\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T11:30:49.607487Z",
     "start_time": "2025-07-28T11:30:49.601320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)\n",
    "print(f'Train X length: {len(X_train)}, Test X length: {len(X_test)} with shapes {X_train[0].shape}, {X_test[0].shape}')\n",
    "print(f'Train y shape: {y_train.shape}, Test y shape: {y_test.shape}')"
   ],
   "id": "b794e14649437223",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X length: 119, Test X length: 30 with shapes torch.Size([101, 116, 96]), torch.Size([101, 116, 96])\n",
      "Train y shape: (119,), Test y shape: (30,)\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T11:30:54.625481Z",
     "start_time": "2025-07-28T11:30:53.147129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the train and test sets\n",
    "torch.save(X_train, 'data/pet_csf/X_train_tplus.pt')\n",
    "torch.save(y_train, 'data/pet_csf/y_train_tplus.pt')\n",
    "torch.save(X_test, 'data/pet_csf/X_test_tplus.pt')\n",
    "torch.save(y_test, 'data/pet_csf/y_test_tplus.pt')"
   ],
   "id": "14bfd98a36ebb40e",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_train = torch.load('data/pet_csf/X_train_tplus.pt', weights_only=False)\n",
    "X_test = torch.load('data/pet_csf/X_test_tplus.pt', weights_only=False)\n",
    "y_train = torch.load('data/pet_csf/y_train_tplus.pt', weights_only=False)\n",
    "y_test = torch.load('data/pet_csf/y_test_tplus.pt', weights_only=False)"
   ],
   "id": "4ab38bca9acf2793"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Test the pretrained model before tuning",
   "id": "d0440f99af5de5fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "batch_size = 2\n",
    "model = DeepPETEncoderGradCAM()\n",
    "model.load_state_dict(torch.load('weights/deeppet.pth', weights_only=True)['model'])\n",
    "model.to(device)"
   ],
   "id": "8d3e0daeeb9d0e02"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Compute the accuracy on the train set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    train_dataset = PETDataset(X_train, y_train)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    y_pred_train = []\n",
    "    y_true_train = []\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
    "        outputs = model(inputs)\n",
    "        y_pred_train.extend(outputs.cpu().numpy())\n",
    "        y_true_train.extend(labels.cpu().numpy())\n",
    "    y_pred_train = (torch.tensor(\n",
    "        y_pred_train) > 0.5).float().numpy()  # Convert probabilities to binary predictions\n",
    "    y_true_train = torch.tensor(y_true_train).numpy()\n",
    "    train_accuracy = accuracy_score(y_true_train, y_pred_train)\n",
    "    train_f1 = f1_score(y_true_train, y_pred_train)\n",
    "    train_roc_auc = roc_auc_score(y_true_train, y_pred_train)\n",
    "    print(\n",
    "        f'Train Accuracy: {train_accuracy:.4f}, Train F1 Score: {train_f1:.4f}, Train ROC AUC: {train_roc_auc:.4f}')"
   ],
   "id": "47dd2536e27cc884"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Compute the accuracy on the test set\n",
    "with torch.no_grad():\n",
    "    test_dataset = PETDataset(X_test, y_test)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    y_pred_test = []\n",
    "    y_true_test = []\n",
    "\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
    "        outputs = model(inputs)\n",
    "        y_pred_test.extend(outputs.cpu().numpy())\n",
    "        y_true_test.extend(labels.cpu().numpy())\n",
    "    y_pred_test = (torch.tensor(\n",
    "        y_pred_test) > 0.5).float().numpy()  # Convert probabilities to binary predictions\n",
    "    y_true_test = torch.tensor(y_true_test).numpy()\n",
    "    test_accuracy = accuracy_score(y_true_test, y_pred_test)\n",
    "    test_f1 = f1_score(y_true_test, y_pred_test)\n",
    "    test_roc_auc = roc_auc_score(y_true_test, y_pred_test)\n",
    "    print(\n",
    "        f'Test Accuracy: {test_accuracy:.4f}, Test F1 Score: {test_f1:.4f}, Test ROC AUC: {test_roc_auc:.4f}')"
   ],
   "id": "56e7ea313d61de66"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Tune the pretrained model",
   "id": "82ed7b48208ca95e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "inputs = torch.stack([torch.unsqueeze(img, 0) for img in X_train], dim=0)  # Add channel dimension\n",
    "labels = torch.tensor(y_train, dtype=torch.float32).unsqueeze(\n",
    "    1)  # Convert labels to float and add a channel dimension\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 100\n",
    "train_losses = []\n",
    "\n",
    "batch_size = 2  # Adjust based on your GPU memory\n",
    "train_dataset = PETDataset(X_train, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "total_batches = len(train_loader)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    batch_counter = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
    "        batch_counter += 1\n",
    "        print(f'Processing batch {batch_counter}/{total_batches} of epoch {epoch}')\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        # print(f'Output shape: {outputs.shape}, Labels shape: {labels.shape}')\n",
    "        # print(f'Output: {outputs[:5]}, Labels: {labels[:5]}')\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "        # Save the best model based on loss\n",
    "        if loss.item() < min(train_losses, default=float('inf')):\n",
    "            torch.save(model.state_dict(), 'weights/best_deeppet_csf_tuned_tplus.pth')\n",
    "    del inputs, labels, outputs  # Clear variables to free memory\n",
    "    torch.cuda.empty_cache()  # Clear GPU memory after each epoch\n",
    "    gc.collect()  # Collect garbage to free up memory\n",
    "\n",
    "    print(f'Epoch [{epoch}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "torch.save(model.state_dict(), 'weights/deeppet_csf_tuned_tplus.pth')"
   ],
   "id": "585d9dadf631e655"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Compute the accuracy on the train set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    train_dataset = PETDataset(X_train, y_train)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    y_pred_train = []\n",
    "    y_true_train = []\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
    "        outputs = model(inputs)\n",
    "        y_pred_train.extend(outputs.cpu().numpy())\n",
    "        y_true_train.extend(labels.cpu().numpy())\n",
    "    y_pred_train = (torch.tensor(\n",
    "        y_pred_train) > 0.5).float().numpy()  # Convert probabilities to binary predictions\n",
    "    y_true_train = torch.tensor(y_true_train).numpy()\n",
    "    train_accuracy = accuracy_score(y_true_train, y_pred_train)\n",
    "    train_f1 = f1_score(y_true_train, y_pred_train)\n",
    "    train_roc_auc = roc_auc_score(y_true_train, y_pred_train)\n",
    "    print(\n",
    "        f'Train Accuracy: {train_accuracy:.4f}, Train F1 Score: {train_f1:.4f}, Train ROC AUC: {train_roc_auc:.4f}')"
   ],
   "id": "1200379ce9cbf120"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Compute the accuracy on the test set\n",
    "with torch.no_grad():\n",
    "    test_dataset = PETDataset(X_test, y_test)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    y_pred_test = []\n",
    "    y_true_test = []\n",
    "\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
    "        outputs = model(inputs)\n",
    "        y_pred_test.extend(outputs.cpu().numpy())\n",
    "        y_true_test.extend(labels.cpu().numpy())\n",
    "    y_pred_test = (torch.tensor(\n",
    "        y_pred_test) > 0.5).float().numpy()  # Convert probabilities to binary predictions\n",
    "    y_true_test = torch.tensor(y_true_test).numpy()\n",
    "    test_accuracy = accuracy_score(y_true_test, y_pred_test)\n",
    "    test_f1 = f1_score(y_true_test, y_pred_test)\n",
    "    test_roc_auc = roc_auc_score(y_true_test, y_pred_test)\n",
    "    print(\n",
    "        f'Test Accuracy: {test_accuracy:.4f}, Test F1 Score: {test_f1:.4f}, Test ROC AUC: {test_roc_auc:.4f}')"
   ],
   "id": "9a3dfc3870a4a076"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Predict N+",
   "id": "513336f430cc5ecb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T11:31:25.748376Z",
     "start_time": "2025-07-28T11:31:25.734981Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Select PET_IMAGE and T+ from df\n",
    "X = df['PET_IMAGE'].tolist()  # This will be a list of torch.Tensor objects\n",
    "y = df['T+'].values     # This will be a numpy array of labels\n",
    "\n",
    "print(f'X length: {len(X)}, PET image shape: {X[0].shape}, y shape: {y.shape}')"
   ],
   "id": "1ca966fc06fb6948",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X length: 149, PET image shape: torch.Size([101, 116, 96]), y shape: (149,)\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T11:31:29.387080Z",
     "start_time": "2025-07-28T11:31:29.378201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)\n",
    "print(f'Train X length: {len(X_train)}, Test X length: {len(X_test)} with shapes {X_train[0].shape}, {X_test[0].shape}')\n",
    "print(f'Train y shape: {y_train.shape}, Test y shape: {y_test.shape}')"
   ],
   "id": "790b175b76dea77e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X length: 119, Test X length: 30 with shapes torch.Size([101, 116, 96]), torch.Size([101, 116, 96])\n",
      "Train y shape: (119,), Test y shape: (30,)\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T11:31:35.538930Z",
     "start_time": "2025-07-28T11:31:33.025903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the train and test sets\n",
    "torch.save(X_train, 'data/pet_csf/X_train_nplus.pt')\n",
    "torch.save(y_train, 'data/pet_csf/y_train_nplus.pt')\n",
    "torch.save(X_test, 'data/pet_csf/X_test_nplus.pt')\n",
    "torch.save(y_test, 'data/pet_csf/y_test_nplus.pt')"
   ],
   "id": "d5fd42204d1284f5",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_train = torch.load('data/pet_csf/X_train_nplus.pt', weights_only=False)\n",
    "X_test = torch.load('data/pet_csf/X_test_nplus.pt', weights_only=False)\n",
    "y_train = torch.load('data/pet_csf/y_train_nplus.pt', weights_only=False)\n",
    "y_test = torch.load('data/pet_csf/y_test_nplus.pt', weights_only=False)"
   ],
   "id": "b0a0675701cad58b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Test the pretrained model before tuning",
   "id": "e47fe2cd3dbb1daa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "batch_size = 2\n",
    "model = DeepPETEncoderGradCAM()\n",
    "model.load_state_dict(torch.load('weights/deeppet.pth', weights_only=True)['model'])\n",
    "model.to(device)"
   ],
   "id": "25e7127dfe403398"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Compute the accuracy on the train set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    train_dataset = PETDataset(X_train, y_train)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    y_pred_train = []\n",
    "    y_true_train = []\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
    "        outputs = model(inputs)\n",
    "        y_pred_train.extend(outputs.cpu().numpy())\n",
    "        y_true_train.extend(labels.cpu().numpy())\n",
    "    y_pred_train = (torch.tensor(\n",
    "        y_pred_train) > 0.5).float().numpy()  # Convert probabilities to binary predictions\n",
    "    y_true_train = torch.tensor(y_true_train).numpy()\n",
    "    train_accuracy = accuracy_score(y_true_train, y_pred_train)\n",
    "    train_f1 = f1_score(y_true_train, y_pred_train)\n",
    "    train_roc_auc = roc_auc_score(y_true_train, y_pred_train)\n",
    "    print(\n",
    "        f'Train Accuracy: {train_accuracy:.4f}, Train F1 Score: {train_f1:.4f}, Train ROC AUC: {train_roc_auc:.4f}')"
   ],
   "id": "38c9a50af45c56e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Compute the accuracy on the test set\n",
    "with torch.no_grad():\n",
    "    test_dataset = PETDataset(X_test, y_test)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    y_pred_test = []\n",
    "    y_true_test = []\n",
    "\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
    "        outputs = model(inputs)\n",
    "        y_pred_test.extend(outputs.cpu().numpy())\n",
    "        y_true_test.extend(labels.cpu().numpy())\n",
    "    y_pred_test = (torch.tensor(\n",
    "        y_pred_test) > 0.5).float().numpy()  # Convert probabilities to binary predictions\n",
    "    y_true_test = torch.tensor(y_true_test).numpy()\n",
    "    test_accuracy = accuracy_score(y_true_test, y_pred_test)\n",
    "    test_f1 = f1_score(y_true_test, y_pred_test)\n",
    "    test_roc_auc = roc_auc_score(y_true_test, y_pred_test)\n",
    "    print(\n",
    "        f'Test Accuracy: {test_accuracy:.4f}, Test F1 Score: {test_f1:.4f}, Test ROC AUC: {test_roc_auc:.4f}')"
   ],
   "id": "a32f306c16cfb81d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Tune the pretrained model",
   "id": "b3b7005108732f8b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "inputs = torch.stack([torch.unsqueeze(img, 0) for img in X_train], dim=0)  # Add channel dimension\n",
    "labels = torch.tensor(y_train, dtype=torch.float32).unsqueeze(\n",
    "    1)  # Convert labels to float and add a channel dimension\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 100\n",
    "train_losses = []\n",
    "\n",
    "batch_size = 2  # Adjust based on your GPU memory\n",
    "train_dataset = PETDataset(X_train, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "total_batches = len(train_loader)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    batch_counter = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
    "        batch_counter += 1\n",
    "        print(f'Processing batch {batch_counter}/{total_batches} of epoch {epoch}')\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        # print(f'Output shape: {outputs.shape}, Labels shape: {labels.shape}')\n",
    "        # print(f'Output: {outputs[:5]}, Labels: {labels[:5]}')\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "        # Save the best model based on loss\n",
    "        if loss.item() < min(train_losses, default=float('inf')):\n",
    "            torch.save(model.state_dict(), 'weights/best_deeppet_csf_tuned_nplus.pth')\n",
    "    del inputs, labels, outputs  # Clear variables to free memory\n",
    "    torch.cuda.empty_cache()  # Clear GPU memory after each epoch\n",
    "    gc.collect()  # Collect garbage to free up memory\n",
    "\n",
    "    print(f'Epoch [{epoch}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "torch.save(model.state_dict(), 'weights/deeppet_csf_tuned_nplus.pth')"
   ],
   "id": "3284b2e77fdc7713"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Compute the accuracy on the train set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    train_dataset = PETDataset(X_train, y_train)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    y_pred_train = []\n",
    "    y_true_train = []\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
    "        outputs = model(inputs)\n",
    "        y_pred_train.extend(outputs.cpu().numpy())\n",
    "        y_true_train.extend(labels.cpu().numpy())\n",
    "    y_pred_train = (torch.tensor(\n",
    "        y_pred_train) > 0.5).float().numpy()  # Convert probabilities to binary predictions\n",
    "    y_true_train = torch.tensor(y_true_train).numpy()\n",
    "    train_accuracy = accuracy_score(y_true_train, y_pred_train)\n",
    "    train_f1 = f1_score(y_true_train, y_pred_train)\n",
    "    train_roc_auc = roc_auc_score(y_true_train, y_pred_train)\n",
    "    print(\n",
    "        f'Train Accuracy: {train_accuracy:.4f}, Train F1 Score: {train_f1:.4f}, Train ROC AUC: {train_roc_auc:.4f}')"
   ],
   "id": "15efd3445e7dd9be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Compute the accuracy on the test set\n",
    "with torch.no_grad():\n",
    "    test_dataset = PETDataset(X_test, y_test)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    y_pred_test = []\n",
    "    y_true_test = []\n",
    "\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
    "        outputs = model(inputs)\n",
    "        y_pred_test.extend(outputs.cpu().numpy())\n",
    "        y_true_test.extend(labels.cpu().numpy())\n",
    "    y_pred_test = (torch.tensor(\n",
    "        y_pred_test) > 0.5).float().numpy()  # Convert probabilities to binary predictions\n",
    "    y_true_test = torch.tensor(y_true_test).numpy()\n",
    "    test_accuracy = accuracy_score(y_true_test, y_pred_test)\n",
    "    test_f1 = f1_score(y_true_test, y_pred_test)\n",
    "    test_roc_auc = roc_auc_score(y_true_test, y_pred_test)\n",
    "    print(\n",
    "        f'Test Accuracy: {test_accuracy:.4f}, Test F1 Score: {test_f1:.4f}, Test ROC AUC: {test_roc_auc:.4f}')"
   ],
   "id": "65fde509e754307e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
